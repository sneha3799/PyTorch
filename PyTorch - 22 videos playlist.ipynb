{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43ea5870",
   "metadata": {},
   "source": [
    "# Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b7da7d",
   "metadata": {},
   "source": [
    "##### Everything in PyTorch is based on tensor operations. A tensor is a multi-dimensional matrix containing elements of a single data type.\n",
    "##### It's similar to a numpy nd array but here we also have gpu support "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d13bb78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db8919f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empty(1) tensor([0.])\n",
      "empty(3) tensor([0., 0., 0.])\n",
      "empty(2,3) tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "empty(2,2,3) tensor([[[0., 0., 0.],\n",
      "         [0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.],\n",
      "         [0., 0., 0.]]])\n"
     ]
    }
   ],
   "source": [
    "# torch.empty(size): uninitialized\n",
    "x = torch.empty(1)\n",
    "print('empty(1)',x)\n",
    "x = torch.empty(3) #vector\n",
    "print('empty(3)',x)\n",
    "x = torch.empty(2,3) #matrix\n",
    "print('empty(2,3)',x)\n",
    "x = torch.empty(2,2,3) #tensor, 3 dimensions\n",
    "print('empty(2,2,3)',x)\n",
    "#x = torch.empty(2,2,2,3) #tensor, 4 dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47ba414a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rand(5,3) -  tensor([[0.0253, 0.6324, 0.7871],\n",
      "        [0.7068, 0.6076, 0.0028],\n",
      "        [0.7346, 0.2642, 0.2722],\n",
      "        [0.4328, 0.4630, 0.1487],\n",
      "        [0.9858, 0.3353, 0.5208]])\n"
     ]
    }
   ],
   "source": [
    "#torch.rand(size) - random numbers [0,1]\n",
    "x = torch.rand(5,3)\n",
    "print('rand(5,3) - ',x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c59bd34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zeros(5,3) -  tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "#torch.zeros(size) - fill with 0\n",
    "# torch.ones(size) - fill with 1\n",
    "x = torch.zeros(5,3)\n",
    "print('zeros(5,3) - ',x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "397ab83f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size torch.Size([5, 3])\n",
      "shape torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "# check size\n",
    "print('size',x.size()) #x.size(0)\n",
    "print('shape', x.shape) #x.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92593e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], dtype=torch.float16)\n",
      "torch.float16\n"
     ]
    }
   ],
   "source": [
    "# check data type\n",
    "print(x.dtype)\n",
    "\n",
    "# specify types, float32 default\n",
    "x = torch.zeros(5, 3, dtype=torch.float16)\n",
    "print(x)\n",
    "\n",
    "# check type\n",
    "print(x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8fb9d5d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.5000, 3.0000]) torch.float32\n"
     ]
    }
   ],
   "source": [
    "# construct from data\n",
    "x = torch.tensor([5.5, 3])\n",
    "print(x, x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c39a67a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.5000, 3.0000], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# requires_grad argument\n",
    "# This will tell pytorch that it will need to calculate the gradients for this tensor\n",
    "# later in your optimization steps\n",
    "# i.e. this is a variable in your model that you want to optimize\n",
    "x = torch.tensor([5.5, 3], requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec2de20c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n",
      "tensor([[0.1028, 0.1471],\n",
      "        [0.3192, 0.1989]])\n",
      "tensor([[1.1028, 1.1471],\n",
      "        [1.3192, 1.1989]])\n"
     ]
    }
   ],
   "source": [
    "# Operations\n",
    "x = torch.ones(2, 2)\n",
    "y = torch.rand(2, 2)\n",
    "\n",
    "# elementwise addition\n",
    "z = x + y\n",
    "# torch.add(x,y)\n",
    "\n",
    "# in place addition, everythin with a trailing underscore is an inplace operation\n",
    "# i.e. it will modify the variable\n",
    "# y.add_(x)\n",
    "\n",
    "print(x)\n",
    "print(y)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "545cce2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subtraction\n",
    "z = x - y\n",
    "z = torch.sub(x, y)\n",
    "\n",
    "# multiplication\n",
    "z = x * y\n",
    "z = torch.mul(x,y)\n",
    "\n",
    "# division\n",
    "z = x / y\n",
    "z = torch.div(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6590ba87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3193, 0.0526, 0.9149],\n",
      "        [0.9271, 0.2461, 0.0282],\n",
      "        [0.3081, 0.2489, 0.6947],\n",
      "        [0.9778, 0.2970, 0.3637],\n",
      "        [0.3689, 0.9449, 0.4048]])\n",
      "x[:, 0] tensor([0.3193, 0.9271, 0.3081, 0.9778, 0.3689])\n",
      "x[1, :] tensor([0.9271, 0.2461, 0.0282])\n",
      "x[1, 1] tensor(0.2461)\n",
      "x[1,1].item() 0.24612373113632202\n"
     ]
    }
   ],
   "source": [
    "# Slicing\n",
    "x = torch.rand(5,3)\n",
    "print(x)\n",
    "print(\"x[:, 0]\", x[:, 0]) # all rows, column 0\n",
    "print(\"x[1, :]\", x[1, :]) # row 1, all columns\n",
    "print(\"x[1, 1]\", x[1,1]) # element at 1, 1\n",
    "\n",
    "# Get the actual value if only 1 element in your tensor\n",
    "print(\"x[1,1].item()\", x[1,1].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e5232d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n"
     ]
    }
   ],
   "source": [
    "# Reshape with torch.view()\n",
    "x = torch.randn(4, 4)\n",
    "y = x.view(16)\n",
    "z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n",
    "# if -1 it pytorch will automatically determine the necessary size\n",
    "print(x.size(), y.size(), z.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "234d8351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n",
      "[1. 1. 1. 1. 1.]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# Convert a Torch tensor to NumPy array \n",
    "\n",
    "a = torch.ones(5)\n",
    "print(a)\n",
    "\n",
    "# torch to numpy with .numpy()\n",
    "b = a.numpy()\n",
    "print(b)\n",
    "print(type(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5314075c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 2., 2., 2., 2.])\n",
      "[2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "# Careful: If the Tensor is on the CPU (not the GPU),\n",
    "# both objects will share the same memory location, so changing one\n",
    "# will also change the other\n",
    "a.add_(1)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ac185576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.]\n",
      "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n",
      "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n",
      "[2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n",
      "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# Convert NumPy array to Torch tensor \n",
    "\n",
    "# numpy to torch with .from_numpy(x), or torch.tensor() to copy it\n",
    "import numpy as np\n",
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "c = torch.tensor(a)\n",
    "print(a)\n",
    "print(b)\n",
    "print(c)\n",
    "\n",
    "# again be careful when modifying\n",
    "a += 1\n",
    "print(a)\n",
    "print(b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac168cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "### By default all tensors are created on the CPU. \n",
    "### But we can also move them to the GPU (if it's available ), or create them directly on the GPU.\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "x = torch.rand(2,2).to(device)  # move tensors to GPU device\n",
    "#x = x.to(\"cpu\")\n",
    "#x = x.to(\"cuda\")  \n",
    "\n",
    "x = torch.rand(2,2, device=device)  # or directy create them on GPU - MORE EFFICIENT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1eb82cf",
   "metadata": {},
   "source": [
    "# Autograd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27385abb",
   "metadata": {},
   "source": [
    "### The autograd package provides automatic differentiation for all operations on Tensors. \n",
    "##### Generally speaking, torch.autograd is an engine for computing the vector-Jacobian product. \n",
    "##### It computes partial derivates while applying the chain rule.\n",
    "##### Set requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "19f25e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.5036,  0.8687, -0.5952], requires_grad=True)\n",
      "tensor([1.4964, 2.8687, 1.4048], grad_fn=<AddBackward0>)\n",
      "<AddBackward0 object at 0x10427f3d0>\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# requires_grad = True -> tracks all operations on the tensor. \n",
    "x = torch.randn(3, requires_grad=True) # forward pass\n",
    "y = x + 2\n",
    "\n",
    "# y was created as a result of an operation, so it has a grad_fn attribute.\n",
    "# grad_fn: references a Function that has created the Tensor\n",
    "print(x) # created by the user -> grad_fn is None\n",
    "print(y)\n",
    "print(y.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "09a1946a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 6.7172, 24.6877,  5.9201], grad_fn=<MulBackward0>)\n",
      "tensor(12.4417, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Do more operations on y\n",
    "z = y * y * 3\n",
    "print(z)\n",
    "z = z.mean() # calculate loss (mean squared etc.)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "72f1b798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "tensor([2.9927, 5.7373, 2.8095])\n"
     ]
    }
   ],
   "source": [
    "# Let's compute the gradients with backpropagation\n",
    "# When we finish our computation we can call .backward() and have all the gradients computed automatically.\n",
    "# The gradient for this tensor will be accumulated into .grad attribute.\n",
    "# It is the partial derivate of the function w.r.t. the tensor\n",
    "\n",
    "print(x.grad)\n",
    "z.backward() # back propagation \n",
    "print(x.grad) # dz/dx - gradient of loss w.r.t x\n",
    "\n",
    "# !!! Careful!!! backward() accumulates the gradient for this tensor into .grad attribute.\n",
    "# !!! We need to be careful during optimization !!! optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037970ab",
   "metadata": {},
   "source": [
    "### Stop a tensor from tracking history:\n",
    "\n",
    "##### For example during the training loop when we want to update our weights, or after training during evaluation. These operations should not be part of the gradient computation. To prevent this, we can use:\n",
    "##### x.requires_grad_(False)\n",
    "##### x.detach()\n",
    "##### wrap in with torch.no_grad():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "650b62ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "None\n",
      "True\n",
      "True\n",
      "<SumBackward0 object at 0x10427f6a0>\n"
     ]
    }
   ],
   "source": [
    "# .requires_grad_(...) changes an existing flag in-place.\n",
    "a = torch.randn(2, 2)\n",
    "b = (a * a).sum()\n",
    "print(a.requires_grad)\n",
    "print(b.grad_fn)\n",
    "\n",
    "a.requires_grad_(True)\n",
    "b = (a * a).sum()\n",
    "print(a.requires_grad)\n",
    "print(a.requires_grad)\n",
    "print(b.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "374d9052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# .detach(): get a new Tensor with the same content but no gradient computation:\n",
    "a = torch.randn(2, 2, requires_grad=True)\n",
    "b = a.detach()\n",
    "print(a.requires_grad)\n",
    "print(b.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bcd3ff69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# wrap in 'with torch.no_grad():'\n",
    "a = torch.randn(2, 2, requires_grad=True)\n",
    "print(a.requires_grad)\n",
    "with torch.no_grad():\n",
    "    b = a ** 2\n",
    "    print(b.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441c5467",
   "metadata": {},
   "source": [
    "# Gradient Descent Autograd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19eaec4a",
   "metadata": {},
   "source": [
    "##### Linear Regression example:\n",
    "\n",
    "##### 𝑓(𝑥)=𝑤∗𝑥+𝑏 \n",
    "\n",
    "##### here : f(x) = 2 * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e59c1b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction before training: f(5.0) = 0.000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Linear regression\n",
    "# f = w * x  + b\n",
    "# here : f = 2 * x\n",
    "\n",
    "X = torch.tensor([1, 2, 3, 4, 5, 6, 7, 8], dtype=torch.float32)\n",
    "Y = torch.tensor([2, 4, 6, 8, 10, 12, 14, 16], dtype=torch.float32)\n",
    "\n",
    "w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "# model output\n",
    "def forward(x):\n",
    "    return w * x\n",
    "\n",
    "# loss = MSE\n",
    "def loss(y, y_pred):\n",
    "    return ((y_pred - y)**2).mean()\n",
    "\n",
    "X_test = 5.0\n",
    "\n",
    "print(f'Prediction before training: f({X_test}) = {forward(X_test).item():.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a08a1529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10: w = 1.998, loss = 0.000\n",
      "epoch 20: w = 2.000, loss = 0.000\n",
      "epoch 30: w = 2.000, loss = 0.000\n",
      "epoch 40: w = 2.000, loss = 0.000\n",
      "epoch 50: w = 2.000, loss = 0.000\n",
      "epoch 60: w = 2.000, loss = 0.000\n",
      "epoch 70: w = 2.000, loss = 0.000\n",
      "epoch 80: w = 2.000, loss = 0.000\n",
      "epoch 90: w = 2.000, loss = 0.000\n",
      "epoch 100: w = 2.000, loss = 0.000\n",
      "Prediction after training: f(5.0) = 10.000\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "learning_rate = 0.01\n",
    "n_epochs = 100\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # predict = forward pass\n",
    "    y_pred = forward(X)\n",
    "\n",
    "    # loss\n",
    "    l = loss(Y, y_pred)\n",
    "\n",
    "    # calculate gradients = backward pass\n",
    "    l.backward()\n",
    "\n",
    "    # update weights\n",
    "    #w.data = w.data - learning_rate * w.grad\n",
    "    with torch.no_grad():\n",
    "      w -= learning_rate * w.grad\n",
    "    \n",
    "    # zero the gradients after updating\n",
    "    w.grad.zero_()\n",
    "\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'epoch {epoch+1}: w = {w.item():.3f}, loss = {l.item():.3f}')\n",
    "\n",
    "print(f'Prediction after training: f({X_test}) = {forward(X_test).item():.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f937f5a0",
   "metadata": {},
   "source": [
    "# Model, Loss & Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fb86a6",
   "metadata": {},
   "source": [
    "##### A typical PyTorch pipeline looks like this:\n",
    "\n",
    "##### Design model (input, output, forward pass with different layers)\n",
    "##### Construct loss and optimizer\n",
    "##### Training loop:\n",
    "##### Forward = compute prediction and loss\n",
    "##### Backward = compute gradients\n",
    "##### Update weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0f4236e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_samples = 8, n_features = 1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Linear regression\n",
    "# f = w * x \n",
    "# here : f = 2 * x\n",
    "\n",
    "# 0) Training samples, watch the shape!\n",
    "X = torch.tensor([[1], [2], [3], [4], [5], [6], [7], [8]], dtype=torch.float32)\n",
    "Y = torch.tensor([[2], [4], [6], [8], [10], [12], [14], [16]], dtype=torch.float32)\n",
    "\n",
    "n_samples, n_features = X.shape\n",
    "print(f'n_samples = {n_samples}, n_features = {n_features}')\n",
    "\n",
    "# 0) create a test sample\n",
    "X_test = torch.tensor([5], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "68205bae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction before training: f(5.0) = -3.720\n",
      "epoch  10 : w =  1.790800929069519  loss =  0.2832687199115753\n",
      "epoch  20 : w =  1.800475001335144  loss =  0.2612268030643463\n",
      "epoch  30 : w =  1.8083000183105469  loss =  0.24114125967025757\n",
      "epoch  40 : w =  1.8158173561096191  loss =  0.22259986400604248\n",
      "epoch  50 : w =  1.8230397701263428  loss =  0.2054842710494995\n",
      "epoch  60 : w =  1.8299790620803833  loss =  0.18968459963798523\n",
      "epoch  70 : w =  1.8366461992263794  loss =  0.17509980499744415\n",
      "epoch  80 : w =  1.8430519104003906  loss =  0.16163642704486847\n",
      "epoch  90 : w =  1.8492064476013184  loss =  0.149208202958107\n",
      "epoch  100 : w =  1.8551195859909058  loss =  0.13773564994335175\n",
      "Prediction after training: f(5.0) = 10.090\n"
     ]
    }
   ],
   "source": [
    "# 1) Design Model, the model has to implement the forward pass!\n",
    "\n",
    "# Here we could simply use a built-in model from PyTorch\n",
    "# model = nn.Linear(input_size, output_size)\n",
    "\n",
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        # define different layers\n",
    "        self.lin = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.lin(x)\n",
    "\n",
    "\n",
    "input_size, output_size = n_features, n_features\n",
    "\n",
    "model = LinearRegression(input_size, output_size)\n",
    "\n",
    "print(f'Prediction before training: f({X_test.item()}) = {model(X_test).item():.3f}')\n",
    "\n",
    "# 2) Define loss and optimizer\n",
    "learning_rate = 0.01\n",
    "n_epochs = 100\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# 3) Training loop\n",
    "for epoch in range(n_epochs):\n",
    "    # predict = forward pass with our model\n",
    "    y_predicted = model(X)\n",
    "\n",
    "    # loss\n",
    "    l = loss(Y, y_predicted)\n",
    "\n",
    "    # calculate gradients = backward pass\n",
    "    l.backward()\n",
    "\n",
    "    # update weights\n",
    "    optimizer.step()\n",
    "\n",
    "    # zero the gradients after updating\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        w, b = model.parameters() # unpack parameters\n",
    "        print('epoch ', epoch+1, ': w = ', w[0][0].item(), ' loss = ', l.item())\n",
    "\n",
    "print(f'Prediction after training: f({X_test.item()}) = {model(X_test).item():.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555be48b",
   "metadata": {},
   "source": [
    "# First Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5932950f",
   "metadata": {},
   "source": [
    "##### GPU, Datasets, DataLoader, Transforms, Neural Net, Training & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "acbcea13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████| 9912422/9912422 [00:02<00:00, 3867421.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 28881/28881 [00:00<00:00, 298203.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████| 1648877/1648877 [00:00<00:00, 1836343.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 4542/4542 [00:00<00:00, 1668172.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'_SingleProcessDataLoaderIter' object has no attribute 'next'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 38\u001b[0m\n\u001b[1;32m     33\u001b[0m test_loader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(dataset\u001b[38;5;241m=\u001b[39mtest_dataset, \n\u001b[1;32m     34\u001b[0m                                           batch_size\u001b[38;5;241m=\u001b[39mbatch_size, \n\u001b[1;32m     35\u001b[0m                                           shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     37\u001b[0m examples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(test_loader)\n\u001b[0;32m---> 38\u001b[0m example_data, example_targets \u001b[38;5;241m=\u001b[39m examples\u001b[38;5;241m.\u001b[39mnext()\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m6\u001b[39m):\n\u001b[1;32m     41\u001b[0m     plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m,i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: '_SingleProcessDataLoaderIter' object has no attribute 'next'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Hyper-parameters \n",
    "input_size = 784 # 28x28\n",
    "hidden_size = 500 \n",
    "num_classes = 10\n",
    "num_epochs = 2\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "# MNIST dataset \n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', \n",
    "                                           train=True, \n",
    "                                           transform=transforms.ToTensor(),  \n",
    "                                           download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', \n",
    "                                          train=False, \n",
    "                                          transform=transforms.ToTensor())\n",
    "\n",
    "# Data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)\n",
    "\n",
    "examples = iter(test_loader)\n",
    "example_data, example_targets = examples.next()\n",
    "\n",
    "for i in range(6):\n",
    "    plt.subplot(2,3,i+1)\n",
    "    plt.imshow(example_data[i][0], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e76143fe",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hidden_size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;66;03m# no activation and no softmax at the end\u001b[39;00m\n\u001b[1;32m     14\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[0;32m---> 16\u001b[0m model \u001b[38;5;241m=\u001b[39m NeuralNet(input_size, hidden_size, num_classes)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Loss and optimizer\u001b[39;00m\n\u001b[1;32m     19\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'hidden_size' is not defined"
     ]
    }
   ],
   "source": [
    "# Fully connected neural network with one hidden layer\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.l1 = nn.Linear(input_size, hidden_size) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.l2 = nn.Linear(hidden_size, num_classes)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.l1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.l2(out)\n",
    "        # no activation and no softmax at the end\n",
    "        return out\n",
    "\n",
    "model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  \n",
    "\n",
    "# Train the model\n",
    "n_total_steps = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):  \n",
    "        # origin shape: [100, 1, 28, 28]\n",
    "        # resized: [100, 784]\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass and loss calculation\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4e499fa7",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (100x784 and 1x1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m images \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m28\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m28\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      8\u001b[0m labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 10\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(images)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# max returns (output_value ,index)\u001b[39;00m\n\u001b[1;32m     13\u001b[0m _, predicted \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(outputs, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[33], line 13\u001b[0m, in \u001b[0;36mLinearRegression.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin(x)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (100x784 and 1x1)"
     ]
    }
   ],
   "source": [
    "# Test the model: we don't need to compute gradients\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = len(test_loader.dataset)\n",
    "\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "\n",
    "        # max returns (output_value ,index)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        n_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    acc = n_correct / n_samples\n",
    "    print(f'Accuracy of the network on the {n_samples} test images: {100*acc} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3331b75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a7540b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "433218bb",
   "metadata": {},
   "source": [
    "# PyTorch (22 videos playlist - Patrick Loeber)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2fa5b4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd106f5",
   "metadata": {},
   "source": [
    "### Linear Regression - Method 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "25376825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction before training : f(5) = 0.000\n",
      "epoch 1: weight = 1.200, loss = 30.00000000\n",
      "epoch 2: weight = 1.680, loss = 4.79999924\n",
      "epoch 3: weight = 1.872, loss = 0.76800019\n",
      "epoch 4: weight = 1.949, loss = 0.12288000\n",
      "epoch 5: weight = 1.980, loss = 0.01966083\n",
      "epoch 6: weight = 1.992, loss = 0.00314570\n",
      "epoch 7: weight = 1.997, loss = 0.00050332\n",
      "epoch 8: weight = 1.999, loss = 0.00008053\n",
      "epoch 9: weight = 1.999, loss = 0.00001288\n",
      "epoch 10: weight = 2.000, loss = 0.00000206\n",
      "prediction after training: f(5) =  9.999\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression\n",
    "# f = w * x\n",
    "\n",
    "# Method 1 \n",
    "## prediction - manually \n",
    "## gradients computation - manually\n",
    "## loss computation - manually\n",
    "## parameter updates - manually \n",
    "\n",
    "X = np.array([1,2,3,4], dtype=np.float32)\n",
    "Y = np.array([2,4,6,8], dtype=np.float32)\n",
    "\n",
    "w = 0.0\n",
    "\n",
    "# model prediction \n",
    "def forward(x):\n",
    "    return w * x\n",
    "    \n",
    "# loss\n",
    "def loss(y, y_hat):\n",
    "    return ((y_hat - y)**2).mean()\n",
    "\n",
    "# calc gradients\n",
    "# MSE = 1/N * ((w*x - y)**2) => dJ/dw = 2 * x * (w*x - y) * 1/N\n",
    "def gradient(x, y, y_hat):\n",
    "    return np.dot(2*x, y_hat-y).mean()\n",
    "\n",
    "print(f'prediction before training : f(5) = {forward(5):.3f}')\n",
    "\n",
    "# Training \n",
    "learning_rate = 0.01\n",
    "n_iters = 10\n",
    "\n",
    "for epoch in range(n_iters):\n",
    "    # prediction = forward pass\n",
    "    y_pred = forward(X)\n",
    "    \n",
    "    # loss \n",
    "    l = loss(Y, y_pred)\n",
    "    \n",
    "    # gradients \n",
    "    dw = gradient(X, Y, y_pred)\n",
    "    \n",
    "    # update weights \n",
    "    w -= learning_rate * dw\n",
    "    \n",
    "    if epoch%1==0:\n",
    "        print(f'epoch {epoch + 1}: weight = {w:.3f}, loss = {l:.8f}')\n",
    "        \n",
    "print(f'prediction after training: f(5) = {forward(5): .3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae5ec5e",
   "metadata": {},
   "source": [
    "### Linear Regression - Method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c80f9e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction before training : f(5) = 0.000\n",
      "epoch 1: weight = 0.300, loss = 30.00000000\n",
      "epoch 2: weight = 0.555, loss = 21.67499924\n",
      "epoch 3: weight = 0.772, loss = 15.66018772\n",
      "epoch 4: weight = 0.956, loss = 11.31448650\n",
      "epoch 5: weight = 1.113, loss = 8.17471695\n",
      "epoch 6: weight = 1.246, loss = 5.90623236\n",
      "epoch 7: weight = 1.359, loss = 4.26725292\n",
      "epoch 8: weight = 1.455, loss = 3.08308983\n",
      "epoch 9: weight = 1.537, loss = 2.22753215\n",
      "epoch 10: weight = 1.606, loss = 1.60939169\n",
      "prediction after training: f(5) =  8.031\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression\n",
    "# f = w * x\n",
    "\n",
    "# Method 2 \n",
    "## prediction - manually \n",
    "## gradients computation - Autograd\n",
    "## loss computation - manually\n",
    "## parameter updates - manually \n",
    "\n",
    "X = torch.tensor([1,2,3,4], dtype=torch.float32)\n",
    "Y = torch.tensor([2,4,6,8], dtype=torch.float32)\n",
    "\n",
    "w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "# model prediction \n",
    "def forward(x):\n",
    "    return w * x\n",
    "    \n",
    "# loss\n",
    "def loss(y, y_hat):\n",
    "    return ((y_hat - y)**2).mean()\n",
    "\n",
    "print(f'prediction before training : f(5) = {forward(5):.3f}')\n",
    "\n",
    "# Training \n",
    "learning_rate = 0.01\n",
    "n_iters = 10\n",
    "\n",
    "for epoch in range(n_iters):\n",
    "    # prediction = forward pass\n",
    "    y_pred = forward(X)\n",
    "    \n",
    "    # loss \n",
    "    l = loss(Y, y_pred)\n",
    "    \n",
    "    # gradients = backward pass\n",
    "    l.backward() #dl/dw\n",
    "    \n",
    "    # update weights \n",
    "    with torch.no_grad():\n",
    "        w -= learning_rate * w.grad\n",
    "     \n",
    "    # zero gradients\n",
    "    w.grad.zero_()\n",
    "    \n",
    "    if epoch%1==0:\n",
    "        print(f'epoch {epoch + 1}: weight = {w:.3f}, loss = {l:.8f}')\n",
    "        \n",
    "print(f'prediction after training: f(5) = {forward(5): .3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d673b0",
   "metadata": {},
   "source": [
    "### Linear Regression - Method 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f338a4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction before training : f(5) = 0.000\n",
      "epoch 1: weight = 0.300, loss = 30.00000000\n",
      "epoch 11: weight = 1.665, loss = 1.16278565\n",
      "epoch 21: weight = 1.934, loss = 0.04506890\n",
      "epoch 31: weight = 1.987, loss = 0.00174685\n",
      "epoch 41: weight = 1.997, loss = 0.00006770\n",
      "epoch 51: weight = 1.999, loss = 0.00000262\n",
      "epoch 61: weight = 2.000, loss = 0.00000010\n",
      "epoch 71: weight = 2.000, loss = 0.00000000\n",
      "epoch 81: weight = 2.000, loss = 0.00000000\n",
      "epoch 91: weight = 2.000, loss = 0.00000000\n",
      "prediction after training: f(5) =  10.000\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression\n",
    "# f = w * x\n",
    "\n",
    "# Method 3 \n",
    "## prediction - manually \n",
    "## gradients computation - Autograd\n",
    "## loss computation - PyTorch Loss\n",
    "## parameter updates - PyTorch Optimizer \n",
    "\n",
    "X = torch.tensor([1,2,3,4], dtype=torch.float32)\n",
    "Y = torch.tensor([2,4,6,8], dtype=torch.float32)\n",
    "\n",
    "w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "# model prediction \n",
    "def forward(x):\n",
    "    return w * x \n",
    "\n",
    "print(f'prediction before training : f(5) = {forward(5):.3f}')\n",
    "\n",
    "# Training \n",
    "learning_rate = 0.01\n",
    "n_iters = 100\n",
    "loss = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD([w], lr=learning_rate)\n",
    "\n",
    "for epoch in range(n_iters):\n",
    "    # prediction = forward pass\n",
    "    y_pred = forward(X)\n",
    "    \n",
    "    # loss \n",
    "    l = loss(Y, y_pred)\n",
    "    \n",
    "    # gradients = backward pass\n",
    "    l.backward() #dl/dw\n",
    "    \n",
    "    # update weights \n",
    "    optimizer.step()\n",
    "     \n",
    "    # zero gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    if epoch%10==0:\n",
    "        print(f'epoch {epoch + 1}: weight = {w:.3f}, loss = {l:.8f}')\n",
    "        \n",
    "print(f'prediction after training: f(5) = {forward(5): .3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674cc8b6",
   "metadata": {},
   "source": [
    "### Linear Regression - Method 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4d26bab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction before training : f(5) = -0.380\n",
      "epoch 1: weight = 0.020, loss = 28.54846573\n",
      "epoch 11: weight = 1.251, loss = 1.11544967\n",
      "epoch 21: weight = 1.461, loss = 0.38375831\n",
      "epoch 31: weight = 1.508, loss = 0.34417069\n",
      "epoch 41: weight = 1.527, loss = 0.32369179\n",
      "epoch 51: weight = 1.542, loss = 0.30483976\n",
      "epoch 61: weight = 1.555, loss = 0.28709593\n",
      "epoch 71: weight = 1.569, loss = 0.27038556\n",
      "epoch 81: weight = 1.581, loss = 0.25464761\n",
      "epoch 91: weight = 1.594, loss = 0.23982583\n",
      "prediction after training: f(5) =  9.185\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression\n",
    "# f = w * x\n",
    "\n",
    "# Method 4 \n",
    "## prediction - PyTorch Model \n",
    "## gradients computation - Autograd\n",
    "## loss computation - PyTorch Loss\n",
    "## parameter updates - PyTorch Optimizer \n",
    "\n",
    "X = torch.tensor([[1],[2],[3],[4]], dtype=torch.float32)\n",
    "Y = torch.tensor([[2],[4],[6],[8]], dtype=torch.float32)\n",
    "\n",
    "X_test = torch.tensor([5], dtype=torch.float32)\n",
    "\n",
    "n_samples, n_features = X.shape\n",
    "\n",
    "input_size = n_features\n",
    "output_size = n_features\n",
    "\n",
    "model = nn.Linear(input_size, output_size)\n",
    "\n",
    "print(f'prediction before training : f(5) = {model(X_test).item():.3f}')\n",
    "\n",
    "# Training \n",
    "learning_rate = 0.01\n",
    "n_iters = 100\n",
    "loss = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
    "\n",
    "for epoch in range(n_iters):\n",
    "    # prediction = forward pass\n",
    "    y_pred = model(X)\n",
    "    \n",
    "    # loss \n",
    "    l = loss(Y, y_pred)\n",
    "    \n",
    "    # gradients = backward pass\n",
    "    l.backward() #dl/dw\n",
    "    \n",
    "    # update weights \n",
    "    optimizer.step()\n",
    "     \n",
    "    # zero gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    if epoch%10==0:\n",
    "        [w,b] = model.parameters()\n",
    "        print(f'epoch {epoch + 1}: weight = {w[0][0].item():.3f}, loss = {l:.8f}')\n",
    "        \n",
    "print(f'prediction after training: f(5) = {model(X_test).item(): .3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28164238",
   "metadata": {},
   "source": [
    "### Linear Regression in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8c72e6a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, loss: 5861.352, weights: 0.528\n",
      "epoch: 11, loss: 4336.798, weights: 12.596\n",
      "epoch: 21, loss: 3235.527, weights: 22.877\n",
      "epoch: 31, loss: 2439.074, weights: 31.637\n",
      "epoch: 41, loss: 1862.435, weights: 39.102\n",
      "epoch: 51, loss: 1444.517, weights: 45.466\n",
      "epoch: 61, loss: 1141.346, weights: 50.892\n",
      "epoch: 71, loss: 921.223, weights: 55.518\n",
      "epoch: 81, loss: 761.271, weights: 59.464\n",
      "epoch: 91, loss: 644.956, weights: 62.831\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Linear Regression in PyTorch \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import numpy as np\n",
    "from sklearn import datasets \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "# prepare data \n",
    "X_numpy, y_numpy = datasets.make_regression(n_samples = 100, n_features = 1, noise=20, random_state=1)\n",
    "X = torch.from_numpy(X_numpy.astype(np.float32))\n",
    "y = torch.from_numpy(y_numpy.astype(np.float32))\n",
    "y = y.view(y.shape[0], 1) # reshape the tensor\n",
    "\n",
    "n_samples, n_features = X.shape\n",
    "\n",
    "# model\n",
    "input_size = n_features\n",
    "output_size = 1\n",
    "model = nn.Linear(input_size, output_size)\n",
    "\n",
    "# loss and optimizer\n",
    "learning_rate = 0.01\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# training loop\n",
    "n_iters = 100\n",
    "for epoch in range(n_iters):\n",
    "    # forward pass\n",
    "    y_pred = model(X)\n",
    "    \n",
    "    # calc loss\n",
    "    l = criterion(y_pred, y)\n",
    "    \n",
    "    # gradients = backward pass\n",
    "    l.backward() #dl/dw\n",
    "    \n",
    "    # backward pass\n",
    "    optimizer.step()\n",
    "    \n",
    "    # update gradients to 0\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    if epoch%10==0:\n",
    "        [w,b] = model.parameters()\n",
    "        print(f'epoch: {epoch+1}, loss: {l:.3f}, weights: {w[0][0].item():.3f}')\n",
    "        \n",
    "# plot\n",
    "predicted = model(X).detach().numpy() \n",
    "# detach() method generates a new tensor where gradient calc is set to False\n",
    "plt.plot(X_numpy, y_numpy, 'ro')\n",
    "plt.plot(X_numpy, predicted, 'b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc6af4b",
   "metadata": {},
   "source": [
    "### Logistic Regression in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a7d33d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, loss: 0.667\n",
      "epoch: 2, loss: 0.648\n",
      "epoch: 3, loss: 0.631\n",
      "epoch: 4, loss: 0.614\n",
      "epoch: 5, loss: 0.599\n",
      "epoch: 6, loss: 0.584\n",
      "epoch: 7, loss: 0.570\n",
      "epoch: 8, loss: 0.557\n",
      "epoch: 9, loss: 0.544\n",
      "epoch: 10, loss: 0.533\n",
      "accuracy: 0.8509\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression in PyTorch\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn import datasets \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# prepare data\n",
    "bc = datasets.load_breast_cancer()\n",
    "X, y = bc.data, bc.target\n",
    "\n",
    "n_samples, n_features = X.shape\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)\n",
    "\n",
    "# scale (always recommended to do for logistic regression)\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "X_train = torch.from_numpy(X_train.astype(np.float32))\n",
    "X_test = torch.from_numpy(X_test.astype(np.float32))\n",
    "y_train = torch.from_numpy(y_train.astype(np.float32))\n",
    "y_test = torch.from_numpy(y_test.astype(np.float32))\n",
    "\n",
    "y_train = y_train.view(y_train.shape[0],1) # reshape\n",
    "y_test = y_test.view(y_test.shape[0],1) # reshape\n",
    "\n",
    "# define model \n",
    "# f = wx + b, sigmoid at the end\n",
    "class LogisticRegression(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_inputs):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(n_inputs, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y_pred = torch.sigmoid(self.linear(x))\n",
    "        return y_pred\n",
    "    \n",
    "model = LogisticRegression(n_features)\n",
    "\n",
    "# loss and optimizer\n",
    "learning_rate = 0.01\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# training loop\n",
    "n_iters = 10\n",
    "for epoch in range(n_iters):\n",
    "    # forward pass\n",
    "    y_pred = model(X_train)\n",
    "    \n",
    "    # calc loss\n",
    "    l = criterion(y_pred, y_train)\n",
    "    \n",
    "    # backward pass\n",
    "    l.backward()\n",
    "    \n",
    "    # update weights \n",
    "    optimizer.step()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    if epoch%1==0:\n",
    "        print(f'epoch: {epoch+1}, loss: {l:.3f}')\n",
    "        \n",
    "with torch.no_grad():\n",
    "    y_pred = model(X_test)\n",
    "    y_pred_cls = y_pred.round()\n",
    "    acc = y_pred_cls.eq(y_test).sum() / float(y_test.shape[0])\n",
    "    print(f'accuracy: {acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabc20e5",
   "metadata": {},
   "source": [
    "### Dataset and DataLoader in PyTorch (https://github.com/patrickloeber/pytorchTutorial/blob/master/09_dataloader.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e22e94f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.2990e+01, 1.6700e+00, 2.6000e+00, 3.0000e+01, 1.3900e+02, 3.3000e+00,\n",
      "         2.8900e+00, 2.1000e-01, 1.9600e+00, 3.3500e+00, 1.3100e+00, 3.5000e+00,\n",
      "         9.8500e+02],\n",
      "        [1.2600e+01, 2.4600e+00, 2.2000e+00, 1.8500e+01, 9.4000e+01, 1.6200e+00,\n",
      "         6.6000e-01, 6.3000e-01, 9.4000e-01, 7.1000e+00, 7.3000e-01, 1.5800e+00,\n",
      "         6.9500e+02],\n",
      "        [1.3500e+01, 1.8100e+00, 2.6100e+00, 2.0000e+01, 9.6000e+01, 2.5300e+00,\n",
      "         2.6100e+00, 2.8000e-01, 1.6600e+00, 3.5200e+00, 1.1200e+00, 3.8200e+00,\n",
      "         8.4500e+02],\n",
      "        [1.3560e+01, 1.7300e+00, 2.4600e+00, 2.0500e+01, 1.1600e+02, 2.9600e+00,\n",
      "         2.7800e+00, 2.0000e-01, 2.4500e+00, 6.2500e+00, 9.8000e-01, 3.0300e+00,\n",
      "         1.1200e+03]]) tensor([[2.],\n",
      "        [3.],\n",
      "        [1.],\n",
      "        [1.]])\n",
      "178 45\n",
      "epoch: 1/ 2, step: 5/ 45, inputs: torch.Size([4, 13])\n",
      "epoch: 1/ 2, step: 10/ 45, inputs: torch.Size([4, 13])\n",
      "epoch: 1/ 2, step: 15/ 45, inputs: torch.Size([4, 13])\n",
      "epoch: 1/ 2, step: 20/ 45, inputs: torch.Size([4, 13])\n",
      "epoch: 1/ 2, step: 25/ 45, inputs: torch.Size([4, 13])\n",
      "epoch: 1/ 2, step: 30/ 45, inputs: torch.Size([4, 13])\n",
      "epoch: 1/ 2, step: 35/ 45, inputs: torch.Size([4, 13])\n",
      "epoch: 1/ 2, step: 40/ 45, inputs: torch.Size([4, 13])\n",
      "epoch: 1/ 2, step: 45/ 45, inputs: torch.Size([2, 13])\n",
      "epoch: 2/ 2, step: 5/ 45, inputs: torch.Size([4, 13])\n",
      "epoch: 2/ 2, step: 10/ 45, inputs: torch.Size([4, 13])\n",
      "epoch: 2/ 2, step: 15/ 45, inputs: torch.Size([4, 13])\n",
      "epoch: 2/ 2, step: 20/ 45, inputs: torch.Size([4, 13])\n",
      "epoch: 2/ 2, step: 25/ 45, inputs: torch.Size([4, 13])\n",
      "epoch: 2/ 2, step: 30/ 45, inputs: torch.Size([4, 13])\n",
      "epoch: 2/ 2, step: 35/ 45, inputs: torch.Size([4, 13])\n",
      "epoch: 2/ 2, step: 40/ 45, inputs: torch.Size([4, 13])\n",
      "epoch: 2/ 2, step: 45/ 45, inputs: torch.Size([2, 13])\n"
     ]
    }
   ],
   "source": [
    "# Dataset and DataLoader \n",
    "# https://github.com/patrickloeber/pytorchTutorial/blob/master/09_dataloader.py\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "class WineDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        # Data loading\n",
    "        xy = np.loadtxt('wine.csv', delimiter=',', dtype=np.float32, skiprows=1)\n",
    "        self.x = torch.from_numpy(xy[:, 1:])\n",
    "        self.y = torch.from_numpy(xy[:, [0]]) # n_samples, 1\n",
    "        self.n_samples = xy.shape[0]\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        # Dataset[index]\n",
    "        return self.x[index], self.y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        # len(Dataset)\n",
    "        return self.n_samples\n",
    "    \n",
    "dataset = WineDataset()\n",
    "#first_data = dataset[0]\n",
    "#features, labels = first_data\n",
    "#print(features, labels)\n",
    "\n",
    "dataloader = DataLoader(dataset=dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "dataiter = iter(dataloader) # converting DataLoader to an iterator\n",
    "data = next(dataiter)\n",
    "features, labels = data\n",
    "print(features, labels)\n",
    "\n",
    "# dummy training loop\n",
    "num_epochs = 2\n",
    "total_samples = len(dataset)\n",
    "n_iters = math.ceil(total_samples/4)\n",
    "print(total_samples, n_iters)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (inputs, labels) in enumerate(dataloader):\n",
    "        # forward pass, backward pass, update weights\n",
    "        if (i+1)%5==0:\n",
    "            print(f'epoch: {epoch+1}/ {num_epochs}, step: {i+1}/ {n_iters}, inputs: {inputs.shape}')\n",
    "            \n",
    "#torchvision.datasets.MNIST()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cef4cb7",
   "metadata": {},
   "source": [
    "### Dataset transforms (https://github.com/patrickloeber/pytorchTutorial/blob/master/10_transformers.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c42b6ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.4230e+01, 1.7100e+00, 2.4300e+00, 1.5600e+01, 1.2700e+02, 2.8000e+00,\n",
      "        3.0600e+00, 2.8000e-01, 2.2900e+00, 5.6400e+00, 1.0400e+00, 3.9200e+00,\n",
      "        1.0650e+03])\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "tensor([2.8460e+01, 3.4200e+00, 4.8600e+00, 3.1200e+01, 2.5400e+02, 5.6000e+00,\n",
      "        6.1200e+00, 5.6000e-01, 4.5800e+00, 1.1280e+01, 2.0800e+00, 7.8400e+00,\n",
      "        2.1300e+03])\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "# Dataset transforms\n",
    "# https://github.com/patrickloeber/pytorchTutorial/blob/master/10_transformers.py\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "class WineDataset(Dataset):\n",
    "    def __init__(self, transform=None):\n",
    "        # Data loading\n",
    "        xy = np.loadtxt('wine.csv', delimiter=',', dtype=np.float32, skiprows=1)\n",
    "        self.x = xy[:, 1:]\n",
    "        self.y = xy[:, [0]] # n_samples, 1\n",
    "        self.n_samples = xy.shape[0]\n",
    "        \n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        # Dataset[index]\n",
    "        sample = self.x[index], self.y[index]\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample\n",
    "    \n",
    "    def __len__(self):\n",
    "        # len(Dataset)\n",
    "        return self.n_samples\n",
    "  \n",
    "\n",
    "class ToTensor:\n",
    "    \n",
    "    def __call__(self, sample):\n",
    "        inputs, targets = sample\n",
    "        return torch.from_numpy(inputs), torch.from_numpy(targets)\n",
    "    \n",
    "class MulTransform:\n",
    "    \n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "        \n",
    "    def __call__(self, sample):\n",
    "        inputs, targets = sample\n",
    "        inputs *= self.factor\n",
    "        return inputs, targets\n",
    "        \n",
    "dataset = WineDataset(transform = ToTensor())\n",
    "first_data = dataset[0]\n",
    "features, labels = first_data\n",
    "print(features)\n",
    "print(type(features), type(labels))\n",
    "\n",
    "composed = torchvision.transforms.Compose([ToTensor(), MulTransform(2)])\n",
    "dataset = WineDataset(transform = composed)\n",
    "first_data = dataset[0]\n",
    "features, labels = first_data\n",
    "print(features)\n",
    "print(type(features), type(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0099e6",
   "metadata": {},
   "source": [
    "### Softmax and Cross entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d582848b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "softmax numpy: [0.65900114 0.24243297 0.09856589]\n",
      "tensor([0.6590, 0.2424, 0.0986])\n",
      "loss 1 : 0.35667494393873245\n",
      "loss 2 : 2.3025850929940455\n",
      "0.3018244206905365\n",
      "1.6241613626480103\n",
      "torch.return_types.max(\n",
      "values=tensor([2.1000, 2.0000, 3.0000]),\n",
      "indices=tensor([2, 0, 1]))\n",
      "tensor([2, 0, 1]) tensor([0, 2, 1])\n"
     ]
    }
   ],
   "source": [
    "# Softmax and cross-entropy\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "\n",
    "def softmax(x):\n",
    "    return np.exp(x)/ np.sum(np.exp(x))\n",
    "\n",
    "x = np.array([2.0, 1.0, 0.1])\n",
    "outputs = softmax(x)\n",
    "print(f'softmax numpy: {outputs}')\n",
    "\n",
    "x = torch.tensor([2.0, 1.0, 0.1])\n",
    "outputs = torch.softmax(x, dim=0)\n",
    "print(outputs)\n",
    "\n",
    "def cross_entropy(actual, predicted):\n",
    "    return -np.sum(actual * np.log(predicted))\n",
    "\n",
    "Y = np.array([1,0,0])\n",
    "Y_pred_good = np.array([0.7, 0.2, 0.1])\n",
    "Y_pred_bad = np.array([0.1, 0.3, 0.6])\n",
    "l1 = cross_entropy(Y, Y_pred_good)\n",
    "l2 = cross_entropy(Y, Y_pred_bad)\n",
    "print(f'loss 1 : {l1}')\n",
    "print(f'loss 2 : {l2}')\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "Y = torch.tensor([2,0,1])\n",
    "# nsamples x nclasses = 3x3\n",
    "Y_pred_good = torch.tensor([[0.1,1.0,2.1], [2.0,1.0,0.1], [0.1,3.0,0.1]])\n",
    "Y_pred_bad = torch.tensor([[2.1,1.0,0.1], [0.1,1.0,2.1], [0.1,3.0,0.1]])\n",
    "\n",
    "l1 = loss(Y_pred_good, Y)\n",
    "l2 = loss(Y_pred_bad, Y)\n",
    "\n",
    "print(l1.item())\n",
    "print(l2.item())\n",
    "\n",
    "print(torch.max(Y_pred_good, 1))\n",
    "_, predictions1 = torch.max(Y_pred_good, 1)\n",
    "_, predictions2 = torch.max(Y_pred_bad, 1)\n",
    "print(predictions1, predictions2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d150fc",
   "metadata": {},
   "source": [
    "### Feedforward neural network (https://www.youtube.com/watch?v=oPhxf2fXHkQ&list=PLqnslRFeH2UrcDBWF5mfPGpqQDSta6VK4&index=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "413c3fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2/ 2, step 100/ 600, loss 0.3501\n",
      "epoch: 2/ 2, step 200/ 600, loss 0.2741\n",
      "epoch: 2/ 2, step 300/ 600, loss 0.3193\n",
      "epoch: 2/ 2, step 400/ 600, loss 0.2427\n",
      "epoch: 2/ 2, step 500/ 600, loss 0.4421\n",
      "epoch: 2/ 2, step 600/ 600, loss 0.1628\n",
      "epoch: 2/ 2, step 100/ 600, loss 0.4826\n",
      "epoch: 2/ 2, step 200/ 600, loss 0.2081\n",
      "epoch: 2/ 2, step 300/ 600, loss 0.1685\n",
      "epoch: 2/ 2, step 400/ 600, loss 0.2294\n",
      "epoch: 2/ 2, step 500/ 600, loss 0.3428\n",
      "epoch: 2/ 2, step 600/ 600, loss 0.2050\n",
      "accuracy : 94.59\n"
     ]
    }
   ],
   "source": [
    "# MNIST\n",
    "# Dataloader, Transformer\n",
    "# Multilayer Neural Net, activation function \n",
    "# Loss and optimizer\n",
    "# Training loop (batch training)\n",
    "# Model evaluation \n",
    "# GPU support\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from sklearn import datasets\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# hyperparameters\n",
    "input_size = 784 # 28x28\n",
    "batch_size = 100\n",
    "num_epochs = 2\n",
    "num_classes = 10\n",
    "hidden_units = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "# MNIST\n",
    "trainset = torchvision.datasets.MNIST(root='./data/', train=True, download=True, transform=transforms.ToTensor())\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data/', train=False, download=True, transform=transforms.ToTensor())\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "examples = iter(trainloader)\n",
    "samples, labels = next(examples)\n",
    "print(samples.shape, labels.shape)\n",
    "\n",
    "# Visualization\n",
    "for i in range(10):\n",
    "    plt.subplot(2,5,i+1)\n",
    "    plt.imshow(samples[i][0],cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "# Multilayer Neural Net, activation function\n",
    "class NeuralNetwork(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_units, num_classes):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_units)\n",
    "        self.fc2 = nn.Linear(hidden_units, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = torch.relu(self.fc1(x))\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "    \n",
    "model = NeuralNetwork(input_size, hidden_units, num_classes)\n",
    "\n",
    "# Loss and optimizer\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop (batch training)\n",
    "n_total_steps = len(trainloader)\n",
    "for i in range(num_epochs):\n",
    "    for i, (samples, labels) in enumerate(trainloader):\n",
    "        # 100 x 1 x 28 x 28 to 100 x 784\n",
    "        samples = samples.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # forward pass\n",
    "        y_pred = model(samples)\n",
    "        \n",
    "        # calc loss\n",
    "        l = loss(y_pred, labels)\n",
    "        \n",
    "        # backward pass\n",
    "        l.backward()\n",
    "        \n",
    "        # update weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if (i+1)%100==0:\n",
    "            print(f'epoch: {epoch+1}/ {num_epochs}, step {i+1}/ {n_total_steps}, loss {l.item():.4f}')\n",
    "            \n",
    "# Model evaluation \n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    \n",
    "    for i, (images, labels) in enumerate(testloader):\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        y_pred = model(images)\n",
    "        \n",
    "        # value, index\n",
    "        _, predictions = torch.max(y_pred, 1)\n",
    "        n_samples += labels.shape[0]\n",
    "        n_correct += (predictions == labels).sum().item()\n",
    "        \n",
    "    acc = 100 * n_correct/ n_samples\n",
    "    print(f'accuracy : {acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e968f01",
   "metadata": {},
   "source": [
    "### Tensorboard (https://www.youtube.com/watch?v=VJW9wU-1n18&list=PLqnslRFeH2UrcDBWF5mfPGpqQDSta6VK4&index=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "59f93115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorboard in /Users/sneha/anaconda3/lib/python3.11/site-packages (2.15.2)\n",
      "Requirement already satisfied: absl-py>=0.4 in /Users/sneha/anaconda3/lib/python3.11/site-packages (from tensorboard) (2.1.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /Users/sneha/anaconda3/lib/python3.11/site-packages (from tensorboard) (1.62.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/sneha/anaconda3/lib/python3.11/site-packages (from tensorboard) (2.28.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /Users/sneha/anaconda3/lib/python3.11/site-packages (from tensorboard) (1.2.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/sneha/anaconda3/lib/python3.11/site-packages (from tensorboard) (3.4.1)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /Users/sneha/anaconda3/lib/python3.11/site-packages (from tensorboard) (1.24.4)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /Users/sneha/anaconda3/lib/python3.11/site-packages (from tensorboard) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/sneha/anaconda3/lib/python3.11/site-packages (from tensorboard) (2.31.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /Users/sneha/anaconda3/lib/python3.11/site-packages (from tensorboard) (68.0.0)\n",
      "Requirement already satisfied: six>1.9 in /Users/sneha/anaconda3/lib/python3.11/site-packages (from tensorboard) (1.16.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/sneha/anaconda3/lib/python3.11/site-packages (from tensorboard) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/sneha/anaconda3/lib/python3.11/site-packages (from tensorboard) (2.2.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/sneha/anaconda3/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/sneha/anaconda3/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/sneha/anaconda3/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/sneha/anaconda3/lib/python3.11/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/sneha/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/sneha/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/sneha/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/sneha/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/sneha/anaconda3/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/sneha/anaconda3/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/sneha/anaconda3/lib/python3.11/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9c475f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c5e4113c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "WARNING: The --force flag will be removed in a future conda release.\n",
      "         See 'conda update --help' for details about the --force-reinstall\n",
      "         and --clobber flags.\n",
      "\n",
      "\n",
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: \\ \n",
      "The environment is inconsistent, please check the package plan carefully\n",
      "The following packages are causing the inconsistency:\n",
      "\n",
      "  - defaults/osx-arm64::jupyterlab_server==2.22.0=py311hca03da5_0\n",
      "  - defaults/osx-arm64::dask-core==2023.6.0=py311hca03da5_0\n",
      "  - defaults/osx-arm64::scikit-image==0.20.0=py311h313beb8_0\n",
      "  - defaults/osx-arm64::sqlalchemy==2.0.25=py311h80987f9_0\n",
      "  - defaults/noarch::requests-file==1.5.1=pyhd3eb1b0_0\n",
      "  - defaults/osx-arm64::black==23.3.0=py311hca03da5_0\n",
      "  - defaults/osx-arm64::bokeh==3.2.1=py311hb6e6a13_0\n",
      "  - defaults/osx-arm64::_anaconda_depends==2023.09=py311_openblas_1\n",
      "  - defaults/osx-arm64::anaconda-project==0.11.1=py311hca03da5_0\n",
      "  - defaults/osx-arm64::python-lsp-black==1.2.1=py311hca03da5_0\n",
      "  - defaults/osx-arm64::pyqt==5.15.7=py311h313beb8_0\n",
      "  - defaults/noarch::cookiecutter==1.7.3=pyhd3eb1b0_0\n",
      "  - conda-forge/osx-arm64::clickhouse-connect==0.7.11=py311hd3f4193_0\n",
      "  - defaults/osx-arm64::jupyter_console==6.6.3=py311hca03da5_0\n",
      "  - defaults/noarch::argon2-cffi==21.3.0=pyhd3eb1b0_0\n",
      "  - defaults/osx-arm64::anaconda-catalogs==0.2.0=py311hca03da5_0\n",
      "  - pytorch/osx-arm64::torchvision==0.18.0=py311_cpu\n",
      "  - defaults/osx-arm64::notebook==6.5.4=py311hca03da5_1\n",
      "  - defaults/osx-arm64::plotly==5.9.0=py311hca03da5_0\n",
      "  - defaults/osx-arm64::twisted==22.10.0=py311h80987f9_0\n",
      "  - defaults/osx-arm64::nbconvert==6.5.4=py311hca03da5_0\n",
      "  - defaults/osx-arm64::jupyter_server_ydoc==0.8.0=py311hca03da5_1\n",
      "  - defaults/osx-arm64::qtawesome==1.2.2=py311hca03da5_0\n",
      "  - defaults/noarch::pyls-spyder==0.4.0=pyhd3eb1b0_0\n",
      "  - defaults/osx-arm64::dask==2023.6.0=py311hca03da5_0\n",
      "  - defaults/osx-arm64::jupyterlab==3.6.3=py311hca03da5_0\n",
      "  - defaults/osx-arm64::s3fs==2023.4.0=py311hca03da5_0\n",
      "  - conda-forge/osx-arm64::onnxruntime==1.18.0=py311h66f376b_2_cpu\n",
      "  - defaults/osx-arm64::datasets==2.12.0=py311hca03da5_0\n",
      "  - defaults/osx-arm64::conda-index==0.3.0=py311hca03da5_0\n",
      "  - defaults/osx-arm64::spyder==5.4.3=py311hca03da5_1\n",
      "  - conda-forge/noarch::posthog==3.5.0=pyhd8ed1ab_1\n",
      "  - defaults/osx-arm64::qtpy==2.2.0=py311hca03da5_0\n",
      "  - defaults/osx-arm64::anaconda-navigator==2.5.0=py311hca03da5_0\n",
      "  - defaults/osx-arm64::notebook-shim==0.2.2=py311hca03da5_0\n",
      "  - defaults/osx-arm64::requests-toolbelt==1.0.0=py311hca03da5_0\n",
      "  - defaults/osx-arm64::scikit-learn==1.3.0=py311h7aedaa7_0\n",
      "  - conda-forge/noarch::h11==0.14.0=pyhd8ed1ab_0\n",
      "  - defaults/osx-arm64::jupyter_server==1.23.4=py311hca03da5_0\n",
      "  - defaults/osx-arm64::xarray==2023.6.0=py311hca03da5_0\n",
      "  - defaults/osx-arm64::nbclassic==0.5.5=py311hca03da5_0\n",
      "  - defaults/osx-arm64::jupyter_server_fileid==0.9.0=py311hca03da5_0\n",
      "  - defaults/osx-arm64::hvplot==0.8.4=py311hca03da5_0\n",
      "  - defaults/osx-arm64::conda-build==3.26.1=py311hca03da5_0\n",
      "  - defaults/osx-arm64::pytest==7.4.0=py311hca03da5_0\n",
      "  - defaults/osx-arm64::qtconsole==5.4.2=py311hca03da5_0\n",
      "  - defaults/osx-arm64::python-lsp-server==1.7.2=py311hca03da5_0\n",
      "  - defaults/osx-arm64::aiobotocore==2.5.0=py311hca03da5_0\n",
      "  - defaults/osx-arm64::statsmodels==0.14.0=py311hb9f6ed7_0\n",
      "  - defaults/osx-arm64::pyqtwebengine==5.15.7=py311h313beb8_0\n",
      "  - pytorch/osx-arm64::pytorch==2.3.0=py3.11_0\n",
      "  - defaults/noarch::responses==0.13.3=pyhd3eb1b0_0\n",
      "  - defaults/osx-arm64::anaconda-cloud-auth==0.1.3=py311hca03da5_0\n",
      "  - defaults/osx-arm64::datashader==0.15.2=py311hca03da5_0\n",
      "  - defaults/osx-arm64::anaconda-client==1.12.1=py311hca03da5_0\n",
      "  - defaults/osx-arm64::typing-extensions==4.7.1=py311hca03da5_0\n",
      "  - defaults/osx-arm64::pyqt5-sip==12.11.0=py311h313beb8_0\n",
      "  - defaults/osx-arm64::imbalanced-learn==0.10.1=py311hca03da5_1\n",
      "  - defaults/osx-arm64::conda-libmamba-solver==23.7.0=py311hca03da5_0\n",
      "  - defaults/osx-arm64::astropy==5.1=py311ha0d4635_0\n",
      "  - defaults/osx-arm64::pydantic==1.10.8=py311h80987f9_0\n",
      "  - defaults/osx-arm64::pytables==3.8.0=py311he080bb3_3\n",
      "  - defaults/osx-arm64::botocore==1.29.76=py311hca03da5_0\n",
      "  - defaults/noarch::bleach==4.1.0=pyhd3eb1b0_0\n",
      "  - defaults/osx-arm64::sphinx==5.0.2=py311hca03da5_0\n",
      "  - defaults/osx-arm64::scrapy==2.8.0=py311hca03da5_0\n",
      "  - conda-forge/osx-arm64::uvicorn==0.30.1=py311h267d04e_0\n",
      "  - defaults/osx-arm64::panel==1.2.3=py311hca03da5_0\n",
      "  - defaults/osx-arm64::pytoolconfig==1.2.5=py311hca03da5_1\n",
      "  - defaults/osx-arm64::numpydoc==1.5.0=py311hca03da5_0\n",
      "  - defaults/osx-arm64::conda-repo-cli==1.0.75=py311hca03da5_0\n",
      "  - defaults/osx-arm64::spyder-kernels==2.4.4=py311hca03da5_0\n",
      "  - conda-forge/noarch::chromadb==0.3.25=pyhd8ed1ab_0\n",
      "  - defaults/osx-arm64::holoviews==1.17.1=py311hca03da5_0\n",
      "  - defaults/osx-arm64::gensim==4.3.0=py311h6956b77_0\n",
      "  - defaults/osx-arm64::ipywidgets==8.0.4=py311hca03da5_0\n",
      "  - defaults/osx-arm64::rope==1.7.0=py311hca03da5_0\n",
      "  - defaults/noarch::aioitertools==0.7.1=pyhd3eb1b0_0\n",
      "  - defaults/osx-arm64::ipykernel==6.25.0=py311hb6e6a13_0\n",
      "  - defaults/osx-arm64::matplotlib-base==3.7.2=py311h7aedaa7_0\n",
      "  - defaults/osx-arm64::conda==23.7.4=py311hca03da5_0\n",
      "  - defaults/osx-arm64::seaborn==0.12.2=py311hca03da5_0\n",
      "  - defaults/osx-arm64::sip==6.6.2=py311h313beb8_0\n",
      "  - defaults/osx-arm64::navigator-updater==0.4.0=py311hca03da5_1\n",
      "  - defaults/noarch::conda-token==0.4.0=pyhd3eb1b0_0\n",
      "  - defaults/osx-arm64::intake==0.6.8=py311hca03da5_0\n",
      "  - defaults/osx-arm64::colorcet==3.0.1=py311hca03da5_0\n",
      "  - defaults/osx-arm64::distributed==2023.6.0=py311hca03da5_0\n",
      "  - defaults/osx-arm64::jupyter==1.0.0=py311hca03da5_8\n",
      "  - conda-forge/noarch::fastapi==0.96.1=pyhd8ed1ab_0\n",
      "  - defaults/osx-arm64::requests==2.31.0=py311hca03da5_0\n",
      "  - defaults/noarch::tldextract==3.2.0=pyhd3eb1b0_0\n",
      "  - defaults/osx-arm64::matplotlib==3.7.2=py311hca03da5_0\n",
      "  - defaults/osx-arm64::pyct==0.5.0=py311hca03da5_0\n",
      "done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 23.7.4\n",
      "  latest version: 24.7.1\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "Or to minimize the number of packages updated during conda update use\n",
      "\n",
      "     conda install conda=24.7.1\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /Users/sneha/anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - conda\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    abseil-cpp-20230802.0      |       h313beb8_2         1.3 MB\n",
      "    aiohttp-3.9.5              |  py311h80987f9_0         813 KB\n",
      "    alabaster-0.7.16           |  py311hca03da5_0          20 KB\n",
      "    arrow-cpp-14.0.2           |       hc7aafb3_1         7.8 MB\n",
      "    attrs-23.1.0               |  py311hca03da5_0         163 KB\n",
      "    autopep8-2.0.4             |     pyhd3eb1b0_0          44 KB\n",
      "    aws-c-auth-0.6.19          |       h80987f9_0          87 KB\n",
      "    aws-c-cal-0.5.20           |       h80987f9_0          39 KB\n",
      "    aws-c-common-0.8.5         |       h80987f9_0         186 KB\n",
      "    aws-c-compression-0.2.16   |       h80987f9_0          18 KB\n",
      "    aws-c-event-stream-0.2.15  |       h313beb8_0          45 KB\n",
      "    aws-c-http-0.6.25          |       h80987f9_0         164 KB\n",
      "    aws-c-io-0.13.10           |       h80987f9_0         133 KB\n",
      "    aws-c-mqtt-0.7.13          |       h80987f9_0          62 KB\n",
      "    aws-c-s3-0.1.51            |       h80987f9_0          63 KB\n",
      "    aws-c-sdkutils-0.1.6       |       h80987f9_0          45 KB\n",
      "    aws-checksums-0.1.13       |       h80987f9_0          48 KB\n",
      "    aws-crt-cpp-0.18.16        |       h313beb8_0         203 KB\n",
      "    aws-sdk-cpp-1.10.55        |       h313beb8_0         2.0 MB\n",
      "    backoff-2.2.1              |  py311hca03da5_1          28 KB\n",
      "    backports-1.1              |     pyhd3eb1b0_1           6 KB\n",
      "    beautifulsoup4-4.12.3      |  py311hca03da5_0         274 KB\n",
      "    blas-2.123                 |         openblas          15 KB  conda-forge\n",
      "    blas-devel-3.9.0           |23_osxarm64_openblas          15 KB  conda-forge\n",
      "    blinker-1.6.2              |  py311hca03da5_0          35 KB\n",
      "    brotli-1.0.9               |       h80987f9_8          20 KB\n",
      "    brotli-bin-1.0.9           |       h80987f9_8          18 KB\n",
      "    brotli-python-1.0.9        |  py311h313beb8_8         367 KB\n",
      "    bzip2-1.0.8                |       h80987f9_6         129 KB\n",
      "    c-blosc2-2.12.0            |       h7df6c2f_0         266 KB\n",
      "    ca-certificates-2024.7.2   |       hca03da5_0         128 KB\n",
      "    certifi-2024.7.4           |  py311hca03da5_0         160 KB\n",
      "    cffi-1.16.0                |  py311h80987f9_1         299 KB\n",
      "    charset-normalizer-3.3.2   |     pyhd3eb1b0_0          44 KB\n",
      "    cloudpickle-3.0.0          |  py311hca03da5_0          42 KB\n",
      "    coloredlogs-15.0.1         |  py311hca03da5_2          82 KB\n",
      "    comm-0.2.1                 |  py311hca03da5_0          18 KB\n",
      "    constantly-23.10.4         |  py311hca03da5_0          33 KB\n",
      "    contourpy-1.2.0            |  py311h48ca7d4_0         255 KB\n",
      "    cryptography-42.0.5        |  py311hd4332d6_1         1.4 MB\n",
      "    cssselect-1.2.0            |  py311hca03da5_0          50 KB\n",
      "    curl-8.7.1                 |       h02f6b3c_0          78 KB\n",
      "    cytoolz-0.12.2             |  py311h80987f9_0         368 KB\n",
      "    flask-3.0.3                |  py311hca03da5_0         217 KB\n",
      "    fmt-9.1.0                  |       h48ca7d4_1         179 KB\n",
      "    fonttools-4.51.0           |  py311h80987f9_0         2.9 MB\n",
      "    frozenlist-1.4.0           |  py311h80987f9_0          48 KB\n",
      "    fsspec-2024.3.1            |  py311hca03da5_0         374 KB\n",
      "    gflags-2.2.2               |       h313beb8_1         125 KB\n",
      "    glib-2.78.4                |       h313beb8_0         507 KB\n",
      "    glib-tools-2.78.4          |       h313beb8_0         106 KB\n",
      "    glog-0.5.0                 |       h313beb8_1          92 KB\n",
      "    greenlet-3.0.1             |  py311h313beb8_0         225 KB\n",
      "    grpc-cpp-1.48.2            |       hc60591f_4         3.0 MB\n",
      "    gtest-1.14.0               |       h48ca7d4_1         390 KB\n",
      "    h5py-3.11.0                |  py311hba6ad2f_0         1.3 MB\n",
      "    huggingface_hub-0.23.1     |  py311hca03da5_0         590 KB\n",
      "    humanfriendly-10.0         |  py311hca03da5_1         153 KB\n",
      "    idna-3.7                   |  py311hca03da5_0         134 KB\n",
      "    imageio-2.33.1             |  py311hca03da5_0         616 KB\n",
      "    importlib-metadata-7.0.1   |  py311hca03da5_0          50 KB\n",
      "    importlib_metadata-7.0.1   |       hd3eb1b0_0           8 KB\n",
      "    incremental-22.10.0        |     pyhd3eb1b0_0          18 KB\n",
      "    ipython-8.25.0             |  py311hca03da5_0         1.4 MB\n",
      "    isort-5.13.2               |  py311hca03da5_0         276 KB\n",
      "    itemloaders-1.1.0          |  py311hca03da5_0          32 KB\n",
      "    jinja2-3.1.4               |  py311hca03da5_0         356 KB\n",
      "    jmespath-1.0.1             |  py311hca03da5_0          50 KB\n",
      "    joblib-1.4.2               |  py311hca03da5_0         533 KB\n",
      "    jpeg-9e                    |       h80987f9_3         245 KB\n",
      "    jsonpatch-1.33             |  py311hca03da5_1          38 KB\n",
      "    jsonschema-4.19.2          |  py311hca03da5_0         195 KB\n",
      "    jsonschema-specifications-2023.7.1|  py311hca03da5_0          17 KB\n",
      "    jupyter_core-5.7.2         |  py311hca03da5_0          98 KB\n",
      "    jupyter_events-0.10.0      |  py311hca03da5_0          43 KB\n",
      "    jupyterlab_pygments-0.2.2  |  py311hca03da5_0          19 KB\n",
      "    jupyterlab_widgets-3.0.10  |  py311hca03da5_0         196 KB\n",
      "    keyring-24.3.1             |  py311hca03da5_0          83 KB\n",
      "    lazy-object-proxy-1.10.0   |  py311h80987f9_0          38 KB\n",
      "    lazy_loader-0.4            |  py311hca03da5_0          25 KB\n",
      "    libarchive-3.6.2           |       h62fee54_3         817 KB\n",
      "    libblas-3.9.0              |23_osxarm64_openblas          15 KB  conda-forge\n",
      "    libbrotlicommon-1.0.9      |       h80987f9_8          70 KB\n",
      "    libbrotlidec-1.0.9         |       h80987f9_8          29 KB\n",
      "    libbrotlienc-1.0.9         |       h80987f9_8         291 KB\n",
      "    libcblas-3.9.0             |23_osxarm64_openblas          15 KB  conda-forge\n",
      "    libcurl-8.7.1              |       h3e2b118_0         366 KB\n",
      "    libcxx-18.1.8              |       h5a72898_4         1.2 MB  conda-forge\n",
      "    libdeflate-1.17            |       h80987f9_1          55 KB\n",
      "    libedit-3.1.20230828       |       h80987f9_0         155 KB\n",
      "    libffi-3.4.4               |       hca03da5_1         120 KB\n",
      "    libgfortran-5.0.0          |13_2_0_hd922786_3         108 KB  conda-forge\n",
      "    libgfortran5-13.2.0        |       hf226fd6_3         974 KB  conda-forge\n",
      "    libglib-2.78.4             |       h0a96307_0         2.7 MB\n",
      "    libiconv-1.16              |       h80987f9_3         735 KB\n",
      "    liblapack-3.9.0            |23_osxarm64_openblas          15 KB  conda-forge\n",
      "    liblapacke-3.9.0           |23_osxarm64_openblas          15 KB  conda-forge\n",
      "    libmamba-1.5.8             |       haeffa04_2         1.3 MB\n",
      "    libmambapy-1.5.8           |  py311h1c5506f_2         282 KB\n",
      "    libnghttp2-1.57.0          |       h62f6fdd_0         634 KB\n",
      "    libopenblas-0.3.27         |openmp_h517c56d_1         2.8 MB  conda-forge\n",
      "    libpq-12.17                |       h02f6b3c_0         2.4 MB\n",
      "    libsolv-0.7.24             |       h514c7bf_1         423 KB\n",
      "    libsqlite-3.46.0           |       hfb93653_0         811 KB  conda-forge\n",
      "    libssh2-1.11.0             |       h3e2b118_0         268 KB\n",
      "    llvm-openmp-18.1.8         |       hde57baf_1         270 KB  conda-forge\n",
      "    llvmlite-0.43.0            |  py311h313beb8_0         406 KB\n",
      "    lxml-5.2.1                 |  py311h50ffb84_0         1.3 MB\n",
      "    lz4-c-1.9.4                |       h313beb8_1         157 KB\n",
      "    markupsafe-2.1.3           |  py311h80987f9_0          26 KB\n",
      "    monotonic-1.5              |             py_0          17 KB\n",
      "    more-itertools-10.1.0      |  py311hca03da5_0         103 KB\n",
      "    multidict-6.0.4            |  py311h80987f9_0          54 KB\n",
      "    nbclient-0.8.0             |  py311hca03da5_0         120 KB\n",
      "    ncurses-6.5                |       h7bae524_1         784 KB  conda-forge\n",
      "    nest-asyncio-1.6.0         |  py311hca03da5_0          18 KB\n",
      "    networkx-3.3               |  py311hca03da5_0         3.1 MB\n",
      "    nltk-3.9.1                 |  py311hca03da5_0         2.8 MB\n",
      "    numba-0.60.0               |  py311h7aedaa7_0         5.9 MB\n",
      "    numexpr-2.8.7              |  py311h6dc990b_0         151 KB\n",
      "    openblas-0.3.27            |openmp_h560b219_1         2.9 MB  conda-forge\n",
      "    openjpeg-2.5.2             |       h54b8e55_0         324 KB\n",
      "    openpyxl-3.1.5             |  py311h80987f9_0         702 KB\n",
      "    overrides-7.4.0            |  py311hca03da5_0          38 KB\n",
      "    packaging-24.1             |  py311hca03da5_0         170 KB\n",
      "    parsel-1.8.1               |  py311hca03da5_0          52 KB\n",
      "    partd-1.4.1                |  py311hca03da5_0          49 KB\n",
      "    patsy-0.5.6                |  py311hca03da5_0         372 KB\n",
      "    pcre2-10.42                |       hb066dcc_1         796 KB\n",
      "    pillow-10.4.0              |  py311h80987f9_0         899 KB\n",
      "    pkginfo-1.10.0             |  py311hca03da5_0          67 KB\n",
      "    prompt-toolkit-3.0.43      |  py311hca03da5_0         735 KB\n",
      "    prompt_toolkit-3.0.43      |       hd3eb1b0_0           5 KB\n",
      "    protobuf-3.20.3            |  py311h313beb8_0         342 KB\n",
      "    py-cpuinfo-9.0.0           |  py311hca03da5_0          65 KB\n",
      "    pyarrow-14.0.2             |  py311ha07b5f9_0         4.2 MB\n",
      "    pycosat-0.6.6              |  py311h80987f9_1          93 KB\n",
      "    pyerfa-2.0.1.4             |  py311hb9f6ed7_0         375 KB\n",
      "    pyjwt-2.8.0                |  py311hca03da5_0          87 KB\n",
      "    pylint-venv-3.0.3          |  py311hca03da5_0          14 KB\n",
      "    pyobjc-core-10.1           |  py311h80987f9_0         492 KB\n",
      "    pyobjc-framework-cocoa-10.1|  py311hb094c41_0         401 KB\n",
      "    pyobjc-framework-coreservices-10.1|  py311hdd8dd1f_0          67 KB\n",
      "    pyobjc-framework-fsevents-10.1|  py311hca03da5_0          17 KB\n",
      "    pyodbc-5.0.1               |  py311h313beb8_0          68 KB\n",
      "    pyopenssl-24.2.1           |  py311hca03da5_0         122 KB\n",
      "    python-dateutil-2.9.0post0 |  py311hca03da5_2         325 KB\n",
      "    python-duckdb-1.0.0        |  py311hb9542d7_0        17.8 MB  conda-forge\n",
      "    python-flatbuffers-24.3.25 |  py311hca03da5_0          74 KB\n",
      "    python-lsp-jsonrpc-1.1.2   |     pyhd3eb1b0_0          12 KB\n",
      "    python_abi-3.11            |          5_cp311           6 KB  conda-forge\n",
      "    pytorch-2.3.0              |gpu_mps_py311hc07fac7_100        54.6 MB\n",
      "    pytz-2024.1                |  py311hca03da5_0         222 KB\n",
      "    pywavelets-1.5.0           |  py311hb9f6ed7_0         3.6 MB\n",
      "    pyyaml-6.0.1               |  py311h80987f9_0         197 KB\n",
      "    queuelib-1.6.2             |  py311hca03da5_0          36 KB\n",
      "    referencing-0.30.2         |  py311hca03da5_0          80 KB\n",
      "    regex-2024.7.24            |  py311h80987f9_0         397 KB\n",
      "    reproc-14.2.4              |       h313beb8_2          28 KB\n",
      "    reproc-cpp-14.2.4          |       h313beb8_2          21 KB\n",
      "    rpds-py-0.10.6             |  py311hf0e4da2_0         312 KB\n",
      "    safetensors-0.4.2          |  py311h62f922a_1         386 KB\n",
      "    send2trash-1.8.2           |  py311hca03da5_0          34 KB\n",
      "    sleef-3.5.1                |       h80987f9_2         357 KB\n",
      "    snappy-1.2.1               |       h313beb8_0          39 KB\n",
      "    sniffio-1.3.0              |  py311hca03da5_0          18 KB\n",
      "    soupsieve-2.5              |  py311hca03da5_0          96 KB\n",
      "    sphinxcontrib-serializinghtml-1.1.10|  py311hca03da5_0          34 KB\n",
      "    sqlite-3.45.3              |       h80987f9_0         1.2 MB\n",
      "    starlette-0.27.0           |  py311hca03da5_0         169 KB\n",
      "    sympy-1.12                 |  py311hca03da5_0        14.4 MB\n",
      "    tabulate-0.9.0             |  py311hca03da5_0          70 KB\n",
      "    tenacity-8.2.3             |  py311hca03da5_0          56 KB\n",
      "    threadpoolctl-3.5.0        |  py311hb6e6a13_0          50 KB\n",
      "    tk-8.6.14                  |       h6ba3021_0         3.3 MB\n",
      "    tornado-6.4.1              |  py311h80987f9_0         887 KB\n",
      "    tqdm-4.66.4                |  py311hb6e6a13_0         166 KB\n",
      "    traitlets-5.14.3           |  py311hca03da5_0         222 KB\n",
      "    transformers-4.41.2        |  py311hca03da5_0        22.1 MB\n",
      "    typing_extensions-4.11.0   |  py311hca03da5_0          75 KB\n",
      "    tzdata-2024a               |       h04d1e81_0         116 KB\n",
      "    ujson-5.10.0               |  py311h313beb8_0         142 KB\n",
      "    unicodedata2-15.1.0        |  py311h80987f9_0         532 KB\n",
      "    urllib3-1.26.19            |  py311hca03da5_0         254 KB\n",
      "    utf8proc-2.6.1             |       h80987f9_1          97 KB\n",
      "    w3lib-2.1.2                |  py311hca03da5_0          46 KB\n",
      "    watchdog-4.0.1             |  py311h80987f9_0         162 KB\n",
      "    websocket-client-1.8.0     |  py311hca03da5_0         119 KB\n",
      "    werkzeug-3.0.3             |  py311hca03da5_0         422 KB\n",
      "    widgetsnbextension-4.0.10  |  py311hca03da5_0         949 KB\n",
      "    xlwings-0.31.4             |  py311hca03da5_0        1021 KB\n",
      "    xz-5.4.6                   |       h80987f9_1         371 KB\n",
      "    yaml-cpp-0.8.0             |       h313beb8_1         473 KB\n",
      "    yarl-1.9.3                 |  py311h80987f9_0         118 KB\n",
      "    zeromq-4.3.5               |       h313beb8_0         306 KB\n",
      "    zict-3.0.0                 |  py311hca03da5_0         121 KB\n",
      "    zipp-3.17.0                |  py311hca03da5_0          26 KB\n",
      "    zstandard-0.22.0           |  py311h1a4646a_0         365 KB\n",
      "    zstd-1.5.5                 |       hd90d995_2         504 KB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:       203.8 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  aws-c-auth         pkgs/main/osx-arm64::aws-c-auth-0.6.19-h80987f9_0 \n",
      "  aws-c-cal          pkgs/main/osx-arm64::aws-c-cal-0.5.20-h80987f9_0 \n",
      "  aws-c-compression  pkgs/main/osx-arm64::aws-c-compression-0.2.16-h80987f9_0 \n",
      "  aws-c-http         pkgs/main/osx-arm64::aws-c-http-0.6.25-h80987f9_0 \n",
      "  aws-c-io           pkgs/main/osx-arm64::aws-c-io-0.13.10-h80987f9_0 \n",
      "  aws-c-mqtt         pkgs/main/osx-arm64::aws-c-mqtt-0.7.13-h80987f9_0 \n",
      "  aws-c-s3           pkgs/main/osx-arm64::aws-c-s3-0.1.51-h80987f9_0 \n",
      "  aws-c-sdkutils     pkgs/main/osx-arm64::aws-c-sdkutils-0.1.6-h80987f9_0 \n",
      "  aws-crt-cpp        pkgs/main/osx-arm64::aws-crt-cpp-0.18.16-h313beb8_0 \n",
      "  bcrypt             pkgs/main/osx-arm64::bcrypt-3.2.0-py311h80987f9_1 \n",
      "  blas-devel         conda-forge/osx-arm64::blas-devel-3.9.0-23_osxarm64_openblas \n",
      "  blinker            pkgs/main/osx-arm64::blinker-1.6.2-py311hca03da5_0 \n",
      "  brotli-python      pkgs/main/osx-arm64::brotli-python-1.0.9-py311h313beb8_8 \n",
      "  fsspec             pkgs/main/osx-arm64::fsspec-2024.3.1-py311hca03da5_0 \n",
      "  glib-tools         pkgs/main/osx-arm64::glib-tools-2.78.4-h313beb8_0 \n",
      "  gtest              pkgs/main/osx-arm64::gtest-1.14.0-h48ca7d4_1 \n",
      "  huggingface_hub    pkgs/main/osx-arm64::huggingface_hub-0.23.1-py311hca03da5_0 \n",
      "  jsonpatch          pkgs/main/osx-arm64::jsonpatch-1.33-py311hca03da5_1 \n",
      "  jsonschema-specif~ pkgs/main/osx-arm64::jsonschema-specifications-2023.7.1-py311hca03da5_0 \n",
      "  libblas            conda-forge/osx-arm64::libblas-3.9.0-23_osxarm64_openblas \n",
      "  libcblas           conda-forge/osx-arm64::libcblas-3.9.0-23_osxarm64_openblas \n",
      "  libglib            pkgs/main/osx-arm64::libglib-2.78.4-h0a96307_0 \n",
      "  liblapack          conda-forge/osx-arm64::liblapack-3.9.0-23_osxarm64_openblas \n",
      "  liblapacke         conda-forge/osx-arm64::liblapacke-3.9.0-23_osxarm64_openblas \n",
      "  openblas           conda-forge/osx-arm64::openblas-0.3.27-openmp_h560b219_1 \n",
      "  packaging          pkgs/main/osx-arm64::packaging-24.1-py311hca03da5_0 \n",
      "  referencing        pkgs/main/osx-arm64::referencing-0.30.2-py311hca03da5_0 \n",
      "  rpds-py            pkgs/main/osx-arm64::rpds-py-0.10.6-py311hf0e4da2_0 \n",
      "  safetensors        pkgs/main/osx-arm64::safetensors-0.4.2-py311h62f922a_1 \n",
      "  scipy              pkgs/main/osx-arm64::scipy-1.13.1-py311hac8794a_0 \n",
      "  sleef              pkgs/main/osx-arm64::sleef-3.5.1-h80987f9_2 \n",
      "  starlette          pkgs/main/osx-arm64::starlette-0.27.0-py311hca03da5_0 \n",
      "  tenacity           pkgs/main/osx-arm64::tenacity-8.2.3-py311hca03da5_0 \n",
      "  tokenizers         pkgs/main/osx-arm64::tokenizers-0.19.1-py311he19d34d_0 \n",
      "  transformers       pkgs/main/osx-arm64::transformers-4.41.2-py311hca03da5_0 \n",
      "  typing_extensions  pkgs/main/osx-arm64::typing_extensions-4.11.0-py311hca03da5_0 \n",
      "  unicodedata2       pkgs/main/osx-arm64::unicodedata2-15.1.0-py311h80987f9_0 \n",
      "  urllib3            pkgs/main/osx-arm64::urllib3-1.26.19-py311hca03da5_0 \n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  abseil-cpp                          20211102.0-hc377ac9_0 --> 20230802.0-h313beb8_2 \n",
      "  aiohttp                             3.8.5-py311h80987f9_0 --> 3.9.5-py311h80987f9_0 \n",
      "  alabaster          pkgs/main/noarch::alabaster-0.7.12-py~ --> pkgs/main/osx-arm64::alabaster-0.7.16-py311hca03da5_0 \n",
      "  arrow-cpp                               11.0.0-hc7aafb3_2 --> 14.0.2-hc7aafb3_1 \n",
      "  attrs                              22.1.0-py311hca03da5_0 --> 23.1.0-py311hca03da5_0 \n",
      "  autopep8                               1.6.0-pyhd3eb1b0_1 --> 2.0.4-pyhd3eb1b0_0 \n",
      "  aws-c-common                             0.6.8-h80987f9_1 --> 0.8.5-h80987f9_0 \n",
      "  aws-c-event-stream                       0.1.6-h313beb8_6 --> 0.2.15-h313beb8_0 \n",
      "  aws-checksums                           0.1.11-h80987f9_2 --> 0.1.13-h80987f9_0 \n",
      "  aws-sdk-cpp                            1.8.185-ha71a6ea_1 --> 1.10.55-h313beb8_0 \n",
      "  backoff            conda-forge/noarch::backoff-2.2.1-pyh~ --> pkgs/main/osx-arm64::backoff-2.2.1-py311hca03da5_1 \n",
      "  backports                                1.1-pyhd3eb1b0_0 --> 1.1-pyhd3eb1b0_1 \n",
      "  beautifulsoup4                     4.12.2-py311hca03da5_0 --> 4.12.3-py311hca03da5_0 \n",
      "  blas                         pkgs/main::blas-1.0-openblas --> conda-forge::blas-2.123-openblas \n",
      "  brotli                                   1.0.9-h1a28f6b_7 --> 1.0.9-h80987f9_8 \n",
      "  brotli-bin                               1.0.9-h1a28f6b_7 --> 1.0.9-h80987f9_8 \n",
      "  bzip2                                    1.0.8-h620ffc9_4 --> 1.0.8-h80987f9_6 \n",
      "  c-blosc2                                 2.8.0-h313beb8_0 --> 2.12.0-h7df6c2f_0 \n",
      "  ca-certificates    conda-forge::ca-certificates-2024.6.2~ --> pkgs/main::ca-certificates-2024.7.2-hca03da5_0 \n",
      "  certifi            conda-forge/noarch::certifi-2024.2.2-~ --> pkgs/main/osx-arm64::certifi-2024.7.4-py311hca03da5_0 \n",
      "  cffi                               1.15.1-py311h80987f9_3 --> 1.16.0-py311h80987f9_1 \n",
      "  charset-normalizer                     2.0.4-pyhd3eb1b0_0 --> 3.3.2-pyhd3eb1b0_0 \n",
      "  cloudpickle                         2.2.1-py311hca03da5_0 --> 3.0.0-py311hca03da5_0 \n",
      "  comm                                0.1.2-py311hca03da5_0 --> 0.2.1-py311hca03da5_0 \n",
      "  constantly                         15.1.0-py311hca03da5_0 --> 23.10.4-py311hca03da5_0 \n",
      "  contourpy                           1.0.5-py311h48ca7d4_0 --> 1.2.0-py311h48ca7d4_0 \n",
      "  cryptography                       41.0.3-py311hd4332d6_0 --> 42.0.5-py311hd4332d6_1 \n",
      "  cssselect          pkgs/main/noarch::cssselect-1.1.0-pyh~ --> pkgs/main/osx-arm64::cssselect-1.2.0-py311hca03da5_0 \n",
      "  curl                                     8.2.1-h02f6b3c_0 --> 8.7.1-h02f6b3c_0 \n",
      "  cytoolz                            0.12.0-py311h80987f9_0 --> 0.12.2-py311h80987f9_0 \n",
      "  flask                               2.2.5-py311hca03da5_0 --> 3.0.3-py311hca03da5_0 \n",
      "  fmt                                      9.1.0-h48ca7d4_0 --> 9.1.0-h48ca7d4_1 \n",
      "  fonttools          pkgs/main/noarch::fonttools-4.25.0-py~ --> pkgs/main/osx-arm64::fonttools-4.51.0-py311h80987f9_0 \n",
      "  frozenlist                          1.3.3-py311h80987f9_0 --> 1.4.0-py311h80987f9_0 \n",
      "  gflags                                   2.2.2-hc377ac9_0 --> 2.2.2-h313beb8_1 \n",
      "  glib                                    2.69.1-h514c7bf_2 --> 2.78.4-h313beb8_0 \n",
      "  glog                                     0.5.0-hc377ac9_0 --> 0.5.0-h313beb8_1 \n",
      "  greenlet                            2.0.1-py311h313beb8_0 --> 3.0.1-py311h313beb8_0 \n",
      "  grpc-cpp                                1.48.2-hc60591f_1 --> 1.48.2-hc60591f_4 \n",
      "  h5py                                3.9.0-py311hba6ad2f_0 --> 3.11.0-py311hba6ad2f_0 \n",
      "  idna                                  3.4-py311hca03da5_0 --> 3.7-py311hca03da5_0 \n",
      "  imageio                            2.31.1-py311hca03da5_0 --> 2.33.1-py311hca03da5_0 \n",
      "  importlib-metadata                  6.0.0-py311hca03da5_0 --> 7.0.1-py311hca03da5_0 \n",
      "  importlib_metadata                       6.0.0-hd3eb1b0_0 --> 7.0.1-hd3eb1b0_0 \n",
      "  incremental                           21.3.0-pyhd3eb1b0_0 --> 22.10.0-pyhd3eb1b0_0 \n",
      "  ipython                            8.15.0-py311hca03da5_0 --> 8.25.0-py311hca03da5_0 \n",
      "  isort              pkgs/main/noarch::isort-5.9.3-pyhd3eb~ --> pkgs/main/osx-arm64::isort-5.13.2-py311hca03da5_0 \n",
      "  itemloaders        pkgs/main/noarch::itemloaders-1.0.4-p~ --> pkgs/main/osx-arm64::itemloaders-1.1.0-py311hca03da5_0 \n",
      "  jinja2                              3.1.2-py311hca03da5_0 --> 3.1.4-py311hca03da5_0 \n",
      "  jmespath           pkgs/main/noarch::jmespath-0.10.0-pyh~ --> pkgs/main/osx-arm64::jmespath-1.0.1-py311hca03da5_0 \n",
      "  joblib                              1.2.0-py311hca03da5_0 --> 1.4.2-py311hca03da5_0 \n",
      "  jpeg                                        9e-h80987f9_1 --> 9e-h80987f9_3 \n",
      "  jsonschema                         4.17.3-py311hca03da5_0 --> 4.19.2-py311hca03da5_0 \n",
      "  jupyter_core                        5.3.0-py311hca03da5_0 --> 5.7.2-py311hca03da5_0 \n",
      "  jupyter_events                      0.6.3-py311hca03da5_0 --> 0.10.0-py311hca03da5_0 \n",
      "  jupyterlab_pygmen~ pkgs/main/noarch::jupyterlab_pygments~ --> pkgs/main/osx-arm64::jupyterlab_pygments-0.2.2-py311hca03da5_0 \n",
      "  jupyterlab_widgets                  3.0.5-py311hca03da5_0 --> 3.0.10-py311hca03da5_0 \n",
      "  keyring                           23.13.1-py311hca03da5_0 --> 24.3.1-py311hca03da5_0 \n",
      "  lazy-object-proxy                   1.6.0-py311h80987f9_0 --> 1.10.0-py311h80987f9_0 \n",
      "  lazy_loader                           0.2-py311hca03da5_0 --> 0.4-py311hca03da5_0 \n",
      "  libarchive                               3.6.2-h62fee54_2 --> 3.6.2-h62fee54_3 \n",
      "  libbrotlicommon                          1.0.9-h1a28f6b_7 --> 1.0.9-h80987f9_8 \n",
      "  libbrotlidec                             1.0.9-h1a28f6b_7 --> 1.0.9-h80987f9_8 \n",
      "  libbrotlienc                             1.0.9-h1a28f6b_7 --> 1.0.9-h80987f9_8 \n",
      "  libcurl                                  8.2.1-h3e2b118_0 --> 8.7.1-h3e2b118_0 \n",
      "  libcxx                                  17.0.6-h5f092b4_0 --> 18.1.8-h5a72898_4 \n",
      "  libdeflate                                1.17-h80987f9_0 --> 1.17-h80987f9_1 \n",
      "  libedit                           3.1.20221030-h80987f9_0 --> 3.1.20230828-h80987f9_0 \n",
      "  libffi                                   3.4.4-hca03da5_0 --> 3.4.4-hca03da5_1 \n",
      "  libgfortran5       pkgs/main::libgfortran5-11.3.0-h00934~ --> conda-forge::libgfortran5-13.2.0-hf226fd6_3 \n",
      "  libiconv                                  1.16-h1a28f6b_2 --> 1.16-h80987f9_3 \n",
      "  libmamba                                 1.5.1-h15e39b3_0 --> 1.5.8-haeffa04_2 \n",
      "  libmambapy                          1.5.1-py311h1c5506f_0 --> 1.5.8-py311h1c5506f_2 \n",
      "  libnghttp2                              1.52.0-h62f6fdd_1 --> 1.57.0-h62f6fdd_0 \n",
      "  libopenblas        pkgs/main::libopenblas-0.3.21-h269037~ --> conda-forge::libopenblas-0.3.27-openmp_h517c56d_1 \n",
      "  libpq                                    12.15-h02f6b3c_1 --> 12.17-h02f6b3c_0 \n",
      "  libsolv                                 0.7.24-h514c7bf_0 --> 0.7.24-h514c7bf_1 \n",
      "  libsqlite                               3.45.3-h091b4b1_0 --> 3.46.0-hfb93653_0 \n",
      "  libssh2                                 1.10.0-h02f6b3c_2 --> 1.11.0-h3e2b118_0 \n",
      "  llvm-openmp        pkgs/main::llvm-openmp-14.0.6-hc6e570~ --> conda-forge::llvm-openmp-18.1.8-hde57baf_1 \n",
      "  llvmlite                           0.40.0-py311h514c7bf_0 --> 0.43.0-py311h313beb8_0 \n",
      "  lxml                                4.9.3-py311h50ffb84_0 --> 5.2.1-py311h50ffb84_0 \n",
      "  lz4-c                                    1.9.4-h313beb8_0 --> 1.9.4-h313beb8_1 \n",
      "  markupsafe                          2.1.1-py311h80987f9_0 --> 2.1.3-py311h80987f9_0 \n",
      "  more-itertools     pkgs/main/noarch::more-itertools-8.12~ --> pkgs/main/osx-arm64::more-itertools-10.1.0-py311hca03da5_0 \n",
      "  multidict                           6.0.2-py311h80987f9_0 --> 6.0.4-py311h80987f9_0 \n",
      "  nbclient                           0.5.13-py311hca03da5_0 --> 0.8.0-py311hca03da5_0 \n",
      "  ncurses                                    6.5-hb89a1cb_0 --> 6.5-h7bae524_1 \n",
      "  nest-asyncio                        1.5.6-py311hca03da5_0 --> 1.6.0-py311hca03da5_0 \n",
      "  networkx                              3.1-py311hca03da5_0 --> 3.3-py311hca03da5_0 \n",
      "  nltk                                3.8.1-py311hca03da5_0 --> 3.9.1-py311hca03da5_0 \n",
      "  numba                              0.57.1-py311h7aedaa7_0 --> 0.60.0-py311h7aedaa7_0 \n",
      "  numexpr                             2.8.4-py311h6dc990b_1 --> 2.8.7-py311h6dc990b_0 \n",
      "  openjpeg                                 2.3.0-h7a6adac_2 --> 2.5.2-h54b8e55_0 \n",
      "  openpyxl                           3.0.10-py311h80987f9_0 --> 3.1.5-py311h80987f9_0 \n",
      "  openssl                                  3.3.0-hfb2fe0b_3 --> 3.3.1-h8359307_3 \n",
      "  pandas             pkgs/main::pandas-2.1.4-py311h7aedaa7~ --> conda-forge::pandas-2.2.2-py311h4b4568b_1 \n",
      "  parsel                              1.6.0-py311hca03da5_0 --> 1.8.1-py311hca03da5_0 \n",
      "  partd                               1.4.0-py311hca03da5_0 --> 1.4.1-py311hca03da5_0 \n",
      "  patsy                               0.5.3-py311hca03da5_0 --> 0.5.6-py311hca03da5_0 \n",
      "  pcre2                                    10.42-hb066dcc_0 --> 10.42-hb066dcc_1 \n",
      "  pillow                              9.4.0-py311h313beb8_1 --> 10.4.0-py311h80987f9_0 \n",
      "  pkginfo                             1.9.6-py311hca03da5_0 --> 1.10.0-py311hca03da5_0 \n",
      "  prompt-toolkit                     3.0.36-py311hca03da5_0 --> 3.0.43-py311hca03da5_0 \n",
      "  prompt_toolkit                          3.0.36-hd3eb1b0_0 --> 3.0.43-hd3eb1b0_0 \n",
      "  py-cpuinfo         pkgs/main/noarch::py-cpuinfo-8.0.0-py~ --> pkgs/main/osx-arm64::py-cpuinfo-9.0.0-py311hca03da5_0 \n",
      "  pyarrow                            11.0.0-py311h7575258_1 --> 14.0.2-py311ha07b5f9_0 \n",
      "  pycosat                             0.6.4-py311h80987f9_0 --> 0.6.6-py311h80987f9_1 \n",
      "  pyerfa                              2.0.0-py311h80987f9_0 --> 2.0.1.4-py311hb9f6ed7_0 \n",
      "  pyjwt                               2.4.0-py311hca03da5_0 --> 2.8.0-py311hca03da5_0 \n",
      "  pylint-venv                         2.3.0-py311hca03da5_0 --> 3.0.3-py311hca03da5_0 \n",
      "  pyobjc-core                           9.0-py311h3eb5a62_1 --> 10.1-py311h80987f9_0 \n",
      "  pyobjc-framework-~                    9.0-py311hb094c41_0 --> 10.1-py311hb094c41_0 \n",
      "  pyobjc-framework-~                    9.0-py311hdd8dd1f_0 --> 10.1-py311hdd8dd1f_0 \n",
      "  pyobjc-framework-~                    9.0-py311hca03da5_0 --> 10.1-py311hca03da5_0 \n",
      "  pyodbc                             4.0.34-py311h313beb8_0 --> 5.0.1-py311h313beb8_0 \n",
      "  pyopenssl                          23.2.0-py311hca03da5_0 --> 24.2.1-py311hca03da5_0 \n",
      "  python-dateutil    pkgs/main/noarch::python-dateutil-2.8~ --> pkgs/main/osx-arm64::python-dateutil-2.9.0post0-py311hca03da5_2 \n",
      "  python-duckdb                      0.10.3-py311hb9542d7_0 --> 1.0.0-py311hb9542d7_0 \n",
      "  python-lsp-jsonrpc                     1.0.0-pyhd3eb1b0_0 --> 1.1.2-pyhd3eb1b0_0 \n",
      "  python_abi                                   3.11-4_cp311 --> 3.11-5_cp311 \n",
      "  pytorch                   pytorch::pytorch-2.3.0-py3.11_0 --> pkgs/main::pytorch-2.3.0-gpu_mps_py311hc07fac7_100 \n",
      "  pytz                         2023.3.post1-py311hca03da5_0 --> 2024.1-py311hca03da5_0 \n",
      "  pywavelets                          1.4.1-py311h80987f9_0 --> 1.5.0-py311hb9f6ed7_0 \n",
      "  pyyaml                                6.0-py311h80987f9_1 --> 6.0.1-py311h80987f9_0 \n",
      "  queuelib                            1.5.0-py311hca03da5_0 --> 1.6.2-py311hca03da5_0 \n",
      "  regex                            2022.7.9-py311h80987f9_0 --> 2024.7.24-py311h80987f9_0 \n",
      "  reproc                                  14.2.4-hc377ac9_1 --> 14.2.4-h313beb8_2 \n",
      "  reproc-cpp                              14.2.4-hc377ac9_1 --> 14.2.4-h313beb8_2 \n",
      "  send2trash         pkgs/main/noarch::send2trash-1.8.0-py~ --> pkgs/main/osx-arm64::send2trash-1.8.2-py311hca03da5_0 \n",
      "  snappy                                   1.1.9-hc377ac9_0 --> 1.2.1-h313beb8_0 \n",
      "  sniffio                             1.2.0-py311hca03da5_1 --> 1.3.0-py311hca03da5_0 \n",
      "  soupsieve                             2.4-py311hca03da5_0 --> 2.5-py311hca03da5_0 \n",
      "  sphinxcontrib-ser~ pkgs/main/noarch::sphinxcontrib-seria~ --> pkgs/main/osx-arm64::sphinxcontrib-serializinghtml-1.1.10-py311hca03da5_0 \n",
      "  sqlite                                  3.41.2-h80987f9_0 --> 3.45.3-h80987f9_0 \n",
      "  sympy                              1.11.1-py311hca03da5_0 --> 1.12-py311hca03da5_0 \n",
      "  tabulate                           0.8.10-py311hca03da5_0 --> 0.9.0-py311hca03da5_0 \n",
      "  threadpoolctl      pkgs/main/noarch::threadpoolctl-2.2.0~ --> pkgs/main/osx-arm64::threadpoolctl-3.5.0-py311hb6e6a13_0 \n",
      "  tk                      conda-forge::tk-8.6.13-h5083fa2_1 --> pkgs/main::tk-8.6.14-h6ba3021_0 \n",
      "  tornado                             6.3.2-py311h80987f9_0 --> 6.4.1-py311h80987f9_0 \n",
      "  tqdm                               4.65.0-py311hb6e6a13_0 --> 4.66.4-py311hb6e6a13_0 \n",
      "  traitlets                           5.7.1-py311hca03da5_0 --> 5.14.3-py311hca03da5_0 \n",
      "  tzdata                                   2023c-h04d1e81_0 --> 2024a-h04d1e81_0 \n",
      "  ujson                               5.4.0-py311h313beb8_0 --> 5.10.0-py311h313beb8_0 \n",
      "  utf8proc                                 2.6.1-h1a28f6b_0 --> 2.6.1-h80987f9_1 \n",
      "  w3lib              pkgs/main/noarch::w3lib-1.21.0-pyhd3e~ --> pkgs/main/osx-arm64::w3lib-2.1.2-py311hca03da5_0 \n",
      "  watchdog                            2.1.6-py311h80987f9_0 --> 4.0.1-py311h80987f9_0 \n",
      "  websocket-client                   0.58.0-py311hca03da5_4 --> 1.8.0-py311hca03da5_0 \n",
      "  werkzeug                            2.2.3-py311hca03da5_0 --> 3.0.3-py311hca03da5_0 \n",
      "  widgetsnbextension                  4.0.5-py311hca03da5_0 --> 4.0.10-py311hca03da5_0 \n",
      "  xlwings                            0.29.1-py311hca03da5_0 --> 0.31.4-py311hca03da5_0 \n",
      "  xz                                       5.4.2-h80987f9_0 --> 5.4.6-h80987f9_1 \n",
      "  yaml-cpp                                 0.7.0-hc377ac9_1 --> 0.8.0-h313beb8_1 \n",
      "  yarl                                1.8.1-py311h80987f9_0 --> 1.9.3-py311h80987f9_0 \n",
      "  zeromq                                   4.3.4-hc377ac9_0 --> 4.3.5-h313beb8_0 \n",
      "  zict                                2.2.0-py311hca03da5_0 --> 3.0.0-py311hca03da5_0 \n",
      "  zipp                               3.11.0-py311hca03da5_0 --> 3.17.0-py311hca03da5_0 \n",
      "  zstandard                          0.19.0-py311h80987f9_0 --> 0.22.0-py311h1a4646a_0 \n",
      "  zstd                                     1.5.5-hd90d995_0 --> 1.5.5-hd90d995_2 \n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "  coloredlogs        conda-forge/noarch::coloredlogs-15.0.~ --> pkgs/main/osx-arm64::coloredlogs-15.0.1-py311hca03da5_2 \n",
      "  humanfriendly      conda-forge/noarch::humanfriendly-10.~ --> pkgs/main/osx-arm64::humanfriendly-10.0-py311hca03da5_1 \n",
      "  libgfortran        pkgs/main::libgfortran-5.0.0-11_3_0_h~ --> conda-forge::libgfortran-5.0.0-13_2_0_hd922786_3 \n",
      "  monotonic          conda-forge::monotonic-1.5-pyhd8ed1ab~ --> pkgs/main::monotonic-1.5-py_0 \n",
      "  overrides          conda-forge/noarch::overrides-7.7.0-p~ --> pkgs/main/osx-arm64::overrides-7.4.0-py311hca03da5_0 \n",
      "  protobuf           conda-forge::protobuf-3.20.3-py311ha3~ --> pkgs/main::protobuf-3.20.3-py311h313beb8_0 \n",
      "  python-flatbuffers conda-forge/noarch::python-flatbuffer~ --> pkgs/main/osx-arm64::python-flatbuffers-24.3.25-py311hca03da5_0 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "c-blosc2-2.12.0      | 266 KB    |                                       |   0% \n",
      "libbrotlidec-1.0.9   | 29 KB     |                                       |   0% \u001b[A\n",
      "\n",
      "jupyterlab_pygments- | 19 KB     |                                       |   0% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "protobuf-3.20.3      | 342 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "cssselect-1.2.0      | 50 KB     |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "coloredlogs-15.0.1   | 82 KB     |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "gtest-1.14.0         | 390 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "openpyxl-3.1.5       | 702 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "jsonschema-specifica | 17 KB     |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "aws-sdk-cpp-1.10.55  | 2.0 MB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "lazy_loader-0.4      | 25 KB     |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libssh2-1.11.0       | 268 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "aws-c-cal-0.5.20     | 39 KB     |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pkginfo-1.10.0       | 67 KB     |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "llvm-openmp-18.1.8   | 270 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pyobjc-core-10.1     | 492 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "yaml-cpp-0.8.0       | 473 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "aws-crt-cpp-0.18.16  | 203 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "openjpeg-2.5.2       | 324 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "joblib-1.4.2         | 533 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "gflags-2.2.2         | 125 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "w3lib-2.1.2          | 46 KB     |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "python-flatbuffers-2 | 74 KB     |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "libbrotlidec-1.0.9   | 29 KB     | ##################################### | 100% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "cssselect-1.2.0      | 50 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "cssselect-1.2.0      | 50 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "jupyterlab_pygments- | 19 KB     | ##################################### | 100% \u001b[A\u001b[A\n",
      "\n",
      "c-blosc2-2.12.0      | 266 KB    | ###################9                  |  54% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "c-blosc2-2.12.0      | 266 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "gtest-1.14.0         | 390 KB    | #5                                    |   4% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "coloredlogs-15.0.1   | 82 KB     | #######2                              |  20% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "openpyxl-3.1.5       | 702 KB    | 8                                     |   2% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "jsonschema-specifica | 17 KB     | ###################################5  |  96% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "jsonschema-specifica | 17 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "gtest-1.14.0         | 390 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "aws-sdk-cpp-1.10.55  | 2.0 MB    | 2                                     |   1% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "coloredlogs-15.0.1   | 82 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "protobuf-3.20.3      | 342 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "protobuf-3.20.3      | 342 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "aws-c-cal-0.5.20     | 39 KB     | ###############1                      |  41% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libssh2-1.11.0       | 268 KB    | ##2                                   |   6% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "aws-sdk-cpp-1.10.55  | 2.0 MB    | ##8                                   |   8% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "openpyxl-3.1.5       | 702 KB    | ############6                         |  34% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "lazy_loader-0.4      | 25 KB     | #######################3              |  63% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "aws-c-cal-0.5.20     | 39 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "lazy_loader-0.4      | 25 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pkginfo-1.10.0       | 67 KB     | ########8                             |  24% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pyobjc-core-10.1     | 492 KB    | #2                                    |   3% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "yaml-cpp-0.8.0       | 473 KB    | #2                                    |   3% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "aws-sdk-cpp-1.10.55  | 2.0 MB    | #####################7                |  59% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libssh2-1.11.0       | 268 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libssh2-1.11.0       | 268 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pkginfo-1.10.0       | 67 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "openpyxl-3.1.5       | 702 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "openpyxl-3.1.5       | 702 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "llvm-openmp-18.1.8   | 270 KB    | ##1                                   |   6% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "aws-crt-cpp-0.18.16  | 203 KB    | ##9                                   |   8% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pyobjc-core-10.1     | 492 KB    | #############2                        |  36% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "aws-sdk-cpp-1.10.55  | 2.0 MB    | ##############################9       |  84% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "yaml-cpp-0.8.0       | 473 KB    | #######5                              |  20% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "llvm-openmp-18.1.8   | 270 KB    | ######5                               |  18% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "joblib-1.4.2         | 533 KB    | #1                                    |   3% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "openjpeg-2.5.2       | 324 KB    | #8                                    |   5% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "aws-crt-cpp-0.18.16  | 203 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "w3lib-2.1.2          | 46 KB     | ############9                         |  35% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pyobjc-core-10.1     | 492 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pyobjc-core-10.1     | 492 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "gflags-2.2.2         | 125 KB    | ####7                                 |  13% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "w3lib-2.1.2          | 46 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "yaml-cpp-0.8.0       | 473 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "yaml-cpp-0.8.0       | 473 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "python-flatbuffers-2 | 74 KB     | #######9                              |  22% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "joblib-1.4.2         | 533 KB    | ###################9                  |  54% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "openjpeg-2.5.2       | 324 KB    | #######################7              |  64% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "llvm-openmp-18.1.8   | 270 KB    | ###############3                      |  42% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "gflags-2.2.2         | 125 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "python-flatbuffers-2 | 74 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "openjpeg-2.5.2       | 324 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "joblib-1.4.2         | 533 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "joblib-1.4.2         | 533 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "llvm-openmp-18.1.8   | 270 KB    | ################################9     |  89% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "aws-sdk-cpp-1.10.55  | 2.0 MB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "llvm-openmp-18.1.8   | 270 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \n",
      "                                                                                \u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n"
     ]
    }
   ],
   "source": [
    "!conda update --force conda -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "60fee5ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: / \n",
      "The environment is inconsistent, please check the package plan carefully\n",
      "The following packages are causing the inconsistency:\n",
      "\n",
      "  - defaults/osx-arm64::jupyterlab_server==2.22.0=py311hca03da5_0\n",
      "  - defaults/osx-arm64::sqlalchemy==2.0.25=py311h80987f9_0\n",
      "  - defaults/osx-arm64::tokenizers==0.19.1=py311he19d34d_0\n",
      "  - defaults/osx-arm64::_anaconda_depends==2023.09=py311_openblas_1\n",
      "  - defaults/noarch::argon2-cffi==21.3.0=pyhd3eb1b0_0\n",
      "  - defaults/osx-arm64::notebook==6.5.4=py311hca03da5_1\n",
      "  - defaults/osx-arm64::jupyter_server_ydoc==0.8.0=py311hca03da5_1\n",
      "  - defaults/osx-arm64::jupyterlab==3.6.3=py311hca03da5_0\n",
      "  - defaults/osx-arm64::s3fs==2023.4.0=py311hca03da5_0\n",
      "  - defaults/osx-arm64::datasets==2.12.0=py311hca03da5_0\n",
      "  - defaults/osx-arm64::anaconda-navigator==2.5.0=py311hca03da5_0\n",
      "  - defaults/osx-arm64::notebook-shim==0.2.2=py311hca03da5_0\n",
      "  - defaults/osx-arm64::jupyter_server==1.23.4=py311hca03da5_0\n",
      "  - defaults/osx-arm64::huggingface_hub==0.23.1=py311hca03da5_0\n",
      "  - defaults/osx-arm64::nbclassic==0.5.5=py311hca03da5_0\n",
      "  - defaults/osx-arm64::jupyter_server_fileid==0.9.0=py311hca03da5_0\n",
      "  - defaults/osx-arm64::anaconda-cloud-auth==0.1.3=py311hca03da5_0\n",
      "  - defaults/osx-arm64::typing-extensions==4.7.1=py311hca03da5_0\n",
      "  - defaults/osx-arm64::pydantic==1.10.8=py311h80987f9_0\n",
      "  - conda-forge/noarch::chromadb==0.3.25=pyhd8ed1ab_0\n",
      "  - defaults/osx-arm64::transformers==4.41.2=py311hca03da5_0\n",
      "  - defaults/osx-arm64::jupyter==1.0.0=py311hca03da5_8\n",
      "  - conda-forge/noarch::fastapi==0.96.1=pyhd8ed1ab_0\n",
      "done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 23.7.4\n",
      "  latest version: 24.7.1\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "Or to minimize the number of packages updated during conda update use\n",
      "\n",
      "     conda install conda=24.7.1\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /Users/sneha/anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - werkzeug\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    typing-extensions-4.11.0   |  py311hca03da5_0          10 KB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:          10 KB\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  ca-certificates    pkgs/main::ca-certificates-2024.7.2-h~ --> conda-forge::ca-certificates-2024.7.4-hf0a4a13_0 \n",
      "  typing-extensions                   4.7.1-py311hca03da5_0 --> 4.11.0-py311hca03da5_0 \n",
      "  werkzeug           pkgs/main/osx-arm64::werkzeug-3.0.3-p~ --> conda-forge/noarch::werkzeug-3.0.4-pyhd8ed1ab_0 \n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "  certifi            pkgs/main/osx-arm64::certifi-2024.7.4~ --> conda-forge/noarch::certifi-2024.7.4-pyhd8ed1ab_0 \n",
      "  s3fs               pkgs/main/osx-arm64::s3fs-2023.4.0-py~ --> conda-forge/noarch::s3fs-0.5.1-py_0 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "                                                                                \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n"
     ]
    }
   ],
   "source": [
    "!conda install -c conda-forge werkzeug -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e28445c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "epoch: 1/ 2, step 100/ 600, loss 0.4824\n",
      "epoch: 1/ 2, step 200/ 600, loss 0.4460\n",
      "epoch: 1/ 2, step 300/ 600, loss 0.3095\n",
      "epoch: 1/ 2, step 400/ 600, loss 0.2466\n",
      "epoch: 1/ 2, step 500/ 600, loss 0.2010\n",
      "epoch: 1/ 2, step 600/ 600, loss 0.3258\n",
      "epoch: 2/ 2, step 100/ 600, loss 0.1918\n",
      "epoch: 2/ 2, step 200/ 600, loss 0.1786\n",
      "epoch: 2/ 2, step 300/ 600, loss 0.1597\n",
      "epoch: 2/ 2, step 400/ 600, loss 0.2443\n",
      "epoch: 2/ 2, step 500/ 600, loss 0.3359\n",
      "epoch: 2/ 2, step 600/ 600, loss 0.0871\n",
      "++++ torch.Size([10000, 10])\n",
      "+++++ torch.Size([10000])\n",
      "accuracy : 95.47\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from sklearn import datasets\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "\n",
    "############################# TENSORBOARD ##########################################\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import sys\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter('logs/mnist1')\n",
    "############################# TENSORBOARD ##########################################\n",
    "\n",
    "# device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# hyperparameters\n",
    "input_size = 784 # 28x28\n",
    "batch_size = 100\n",
    "num_epochs = 2\n",
    "num_classes = 10\n",
    "hidden_units = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "# MNIST\n",
    "trainset = torchvision.datasets.MNIST(root='./data/', train=True, download=True, transform=transforms.ToTensor())\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data/', train=False, download=True, transform=transforms.ToTensor())\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "examples = iter(trainloader)\n",
    "samples, labels = next(examples)\n",
    "print(samples.shape, labels.shape)\n",
    "\n",
    "# Visualization\n",
    "for i in range(10):\n",
    "    plt.subplot(2,5,i+1)\n",
    "    plt.imshow(samples[i][0],cmap='gray')\n",
    "#plt.show()\n",
    "\n",
    "############################# TENSORBOARD ##########################################\n",
    "img_grid = torchvision.utils.make_grid(samples)\n",
    "writer.add_image('mnist_images',img_grid)\n",
    "#writer.close()\n",
    "#sys.exit()\n",
    "############################# TENSORBOARD ##########################################\n",
    "\n",
    "# Multilayer Neural Net, activation function\n",
    "class NeuralNetwork(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_units, num_classes):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_units)\n",
    "        self.fc2 = nn.Linear(hidden_units, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = torch.relu(self.fc1(x))\n",
    "        out = self.fc2(out)\n",
    "        # no activation and no softmax at the end\n",
    "        return out\n",
    "    \n",
    "model = NeuralNetwork(input_size, hidden_units, num_classes)\n",
    "\n",
    "# Loss and optimizer\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "############################# TENSORBOARD ##########################################\n",
    "writer.add_graph(model, samples.reshape(-1, 28*28))\n",
    "#writer.close()\n",
    "############################# TENSORBOARD ##########################################\n",
    "\n",
    "# Training loop (batch training)\n",
    "n_total_steps = len(trainloader)\n",
    "running_loss, running_correct = 0.0, 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (samples, labels) in enumerate(trainloader):\n",
    "        # 100 x 1 x 28 x 28 to 100 x 784\n",
    "        samples = samples.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # forward pass\n",
    "        y_pred = model(samples)\n",
    "        \n",
    "        # calc loss\n",
    "        l = loss(y_pred, labels)\n",
    "        \n",
    "        # backward pass\n",
    "        l.backward()\n",
    "        \n",
    "        # update weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        running_loss += l.item()\n",
    "        _, predictions = torch.max(y_pred, 1)\n",
    "        running_correct += (predictions==labels).sum().item()\n",
    "        \n",
    "        if (i+1)%100==0:\n",
    "            print(f'epoch: {epoch+1}/ {num_epochs}, step {i+1}/ {n_total_steps}, loss {l.item():.4f}')\n",
    "            \n",
    "            ############################# TENSORBOARD ##########################################\n",
    "            writer.add_scalar('training loss', running_loss/100, epoch*n_total_steps+i)\n",
    "            running_accuracy = running_correct / 100 / predictions.size(0)\n",
    "            writer.add_scalar('accuracy', running_accuracy, epoch*n_total_steps+i)\n",
    "            running_loss = 0.0\n",
    "            running_correct = 0\n",
    "            ############################# TENSORBOARD ##########################################\n",
    "            \n",
    "# Model evaluation \n",
    "labels = []\n",
    "preds = []\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    \n",
    "    for i, (images, labels1) in enumerate(testloader):\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels1 = labels1.to(device)\n",
    "        \n",
    "        y_pred = model(images)\n",
    "        \n",
    "        # value, index\n",
    "        _, predictions = torch.max(y_pred, 1)\n",
    "        n_samples += labels1.shape[0]\n",
    "        n_correct += (predictions == labels1).sum().item()\n",
    "        \n",
    "        class_predictions = [F.softmax(output, dim=0) for output in y_pred]\n",
    "        preds.append(class_predictions)\n",
    "        labels.append(predictions)\n",
    "        \n",
    "    preds = torch.cat([torch.stack(batch) for batch in preds])    \n",
    "    labels = torch.cat(labels)\n",
    "    print('++++', preds.shape)\n",
    "    print('+++++', labels.shape)\n",
    "        \n",
    "    acc = 100 * n_correct/ n_samples\n",
    "    print(f'accuracy : {acc}')\n",
    "    \n",
    "    classes = range(10)\n",
    "    for i in classes:\n",
    "        labels_i = labels == i\n",
    "        preds_i = preds[:, i]\n",
    "        writer.add_pr_curve(str(i), labels_i, preds_i, global_step=0)\n",
    "        writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9b8d580",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6007 (pid 36649), started 0:13:02 ago. (Use '!kill 36649' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-76fa9f836d8b9f2\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-76fa9f836d8b9f2\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir=logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7387749",
   "metadata": {},
   "source": [
    "### Convolutional Neural Network (https://www.youtube.com/watch?v=pDdP0TFzsoQ&list=PLqnslRFeH2UrcDBWF5mfPGpqQDSta6VK4&index=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d633448a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "torch.Size([4, 3, 32, 32]) torch.Size([4])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/ 4, step 1/12500, loss 2.3258\n",
      "epoch 1/ 4, step 2001/12500, loss 1.4919\n",
      "epoch 1/ 4, step 4001/12500, loss 1.0148\n",
      "epoch 1/ 4, step 6001/12500, loss 1.1393\n",
      "epoch 1/ 4, step 8001/12500, loss 1.8709\n",
      "epoch 1/ 4, step 10001/12500, loss 2.0978\n",
      "epoch 1/ 4, step 12001/12500, loss 0.6572\n",
      "epoch 2/ 4, step 1/12500, loss 2.1632\n",
      "epoch 2/ 4, step 2001/12500, loss 1.6172\n",
      "epoch 2/ 4, step 4001/12500, loss 1.8964\n",
      "epoch 2/ 4, step 6001/12500, loss 1.3731\n",
      "epoch 2/ 4, step 8001/12500, loss 0.8510\n",
      "epoch 2/ 4, step 10001/12500, loss 0.8822\n",
      "epoch 2/ 4, step 12001/12500, loss 1.0662\n",
      "epoch 3/ 4, step 1/12500, loss 1.6474\n",
      "epoch 3/ 4, step 2001/12500, loss 1.5081\n",
      "epoch 3/ 4, step 4001/12500, loss 0.5575\n",
      "epoch 3/ 4, step 6001/12500, loss 3.0259\n",
      "epoch 3/ 4, step 8001/12500, loss 0.8663\n",
      "epoch 3/ 4, step 10001/12500, loss 1.4973\n",
      "epoch 3/ 4, step 12001/12500, loss 1.6984\n",
      "epoch 4/ 4, step 1/12500, loss 0.7347\n",
      "epoch 4/ 4, step 2001/12500, loss 1.5406\n",
      "epoch 4/ 4, step 4001/12500, loss 0.4939\n",
      "epoch 4/ 4, step 6001/12500, loss 0.7233\n",
      "epoch 4/ 4, step 8001/12500, loss 2.3232\n",
      "epoch 4/ 4, step 10001/12500, loss 0.7616\n",
      "epoch 4/ 4, step 12001/12500, loss 1.1497\n",
      "accuracy 61.258\n",
      "Accuracy of plane: 69.34 %\n",
      "Accuracy of car: 70.96 %\n",
      "Accuracy of bird: 42.02 %\n",
      "Accuracy of cat: 45.88 %\n",
      "Accuracy of deer: 57.76 %\n",
      "Accuracy of dog: 56.16 %\n",
      "Accuracy of frog: 62.84 %\n",
      "Accuracy of horse: 68.46 %\n",
      "Accuracy of ship: 59.68 %\n",
      "Accuracy of truck: 79.48 %\n"
     ]
    }
   ],
   "source": [
    "# Convolutional Neural Network\n",
    "\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from sklearn import datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# hyperparameters\n",
    "num_classes = 10\n",
    "num_epochs = 4\n",
    "learning_rate = 0.001\n",
    "batch_size = 4\n",
    "\n",
    "# CIFAR-10\n",
    "transforms = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transforms)\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transforms)\n",
    "testloader = DataLoader(testset, batch_size = batch_size, shuffle=False)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "dataset = iter(trainloader)\n",
    "samples, labels = next(dataset)\n",
    "print(samples.shape, labels.shape)\n",
    "\n",
    "# Visualization\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5  # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "    \n",
    "imshow(torchvision.utils.make_grid(samples))\n",
    "\n",
    "# CNN \n",
    "class CNN(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16*5*5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16*5*5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "        \n",
    "model = CNN().to(device)\n",
    "\n",
    "# Loss and Optimizer\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "n_total_steps = len(trainloader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (samples, labels) in enumerate(trainloader):\n",
    "        # origin shape - [4,3,32,32] = 4,3,1024\n",
    "        # input_layer : 3 input channels, 6 output channels, 5 kernel size\n",
    "        samples = samples.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # forward pass\n",
    "        y_pred = model(samples)\n",
    "        \n",
    "        # calc loss\n",
    "        l = loss(y_pred, labels)\n",
    "        \n",
    "        # backward loss\n",
    "        l.backward()\n",
    "        \n",
    "        # update weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if (i%2000)==0:\n",
    "            print(f'epoch {epoch+1}/ {num_epochs}, step {i+1}/{n_total_steps}, loss {l.item():.4f}')\n",
    "\n",
    "# Model evaluation\n",
    "with torch.no_grad():\n",
    "    n_samples, n_correct = 0, 0\n",
    "    n_class_correct = [0 for i in range(10)]\n",
    "    n_class_samples = [0 for i in range(10)]\n",
    "    for samples, labels in testloader:\n",
    "        samples = samples.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        y_pred = model(samples)\n",
    "\n",
    "        # value, index\n",
    "        _, predictions = torch.max(y_pred, 1)\n",
    "        n_samples += samples.shape[0]\n",
    "        n_correct += (predictions == labels).sum().item()\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            label = labels[i]\n",
    "            pred = predictions[i]\n",
    "            if (label == pred):\n",
    "                n_class_correct[label] += 1\n",
    "            n_class_samples[label] += 1\n",
    "\n",
    "    acc = 100 * n_correct/ n_samples\n",
    "    print(f'accuracy {acc}')\n",
    "    \n",
    "    for i in range(10):\n",
    "            acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n",
    "            print(f'Accuracy of {classes[i]}: {acc} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e75ffe1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
